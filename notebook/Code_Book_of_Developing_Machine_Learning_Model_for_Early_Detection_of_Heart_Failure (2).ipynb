{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3844e679-32f8-47e2-8f28-c8dbaa06c6cc",
      "metadata": {
        "id": "3844e679-32f8-47e2-8f28-c8dbaa06c6cc"
      },
      "source": [
        "# Developing Machine Learning Model for Early Detection of Heart Failure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cba1711a-691b-49b3-bed3-73d7744e0abf",
      "metadata": {
        "id": "cba1711a-691b-49b3-bed3-73d7744e0abf"
      },
      "source": [
        "### Setting up my environment for machine learning with some common libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ea7d3d-850c-434f-a736-70a216d60ce8",
      "metadata": {
        "id": "83ea7d3d-850c-434f-a736-70a216d60ce8"
      },
      "outputs": [],
      "source": [
        "# General Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# Scikit-learn Libraries\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, log_loss, precision_recall_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.feature_selection import RFE, mutual_info_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.cluster import DBSCAN\n",
        "# SciPy Libraries\n",
        "from scipy.stats import fisher_exact\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Statsmodels Library\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from bs4 import BeautifulSoup\n",
        "### Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7ab0c20a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gdown\n",
            "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from gdown)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: requests[socks] in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from gdown) (4.67.1)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
            "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
            "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, PySocks, filelock, beautifulsoup4, gdown\n",
            "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.3 filelock-3.16.1 gdown-5.2.0 soupsieve-2.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a576abdc-e9ae-4937-825e-03784fa336f6",
      "metadata": {
        "id": "a576abdc-e9ae-4937-825e-03784fa336f6"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d772da25-64f5-4bf2-be49-a2be7d1ea026",
      "metadata": {
        "id": "d772da25-64f5-4bf2-be49-a2be7d1ea026"
      },
      "source": [
        "### Load the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6d94f8c-5643-4349-ab58-be8c3fde0dbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "c6d94f8c-5643-4349-ab58-be8c3fde0dbf",
        "outputId": "d91fb4ff-0915-4445-e62a-cd5e22e4c905"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudyID</th>\n",
              "      <th>UHID</th>\n",
              "      <th>SN</th>\n",
              "      <th>Acute Coronary Syndrome  (ACS)</th>\n",
              "      <th>Irregular Heartbeat (Arrhythmia)</th>\n",
              "      <th>Bronchial Asthma (BA)</th>\n",
              "      <th>Coronary Artery Disease (CAD)</th>\n",
              "      <th>Chest X-ray (CXR)</th>\n",
              "      <th>Dyslipidemia : Abnormal Cholesterol Levels (DL)</th>\n",
              "      <th>Diabetes Mellitus (DM)</th>\n",
              "      <th>...</th>\n",
              "      <th>Sodium (mmol/L) (Na)</th>\n",
              "      <th>Random Blood Sugar (mg/dL) (RBS)</th>\n",
              "      <th>Systolic Blood Pressure (mmHg) (SBP)</th>\n",
              "      <th>Total Cholesterol (mg/dL) (TC)</th>\n",
              "      <th>Triglycerides (mg/dL) (TG)</th>\n",
              "      <th>Troponin I (TropI)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Obisity</th>\n",
              "      <th>Chest_pain</th>\n",
              "      <th>Heart Failure (HF)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MPI001</td>\n",
              "      <td>205179</td>\n",
              "      <td>1</td>\n",
              "      <td>ST-Elevation Myocardial Infarction (STEMI)</td>\n",
              "      <td>No Arrhythmia</td>\n",
              "      <td>No</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>140</td>\n",
              "      <td>4.9</td>\n",
              "      <td>180</td>\n",
              "      <td>100</td>\n",
              "      <td>95</td>\n",
              "      <td>0.001</td>\n",
              "      <td>60</td>\n",
              "      <td>Obese</td>\n",
              "      <td>Absent</td>\n",
              "      <td>No HF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MPI002</td>\n",
              "      <td>311074</td>\n",
              "      <td>2</td>\n",
              "      <td>ST-Elevation Myocardial Infarction (STEMI)</td>\n",
              "      <td>No Arrhythmia</td>\n",
              "      <td>No</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>6.5</td>\n",
              "      <td>140</td>\n",
              "      <td>110</td>\n",
              "      <td>85</td>\n",
              "      <td>0.005</td>\n",
              "      <td>64</td>\n",
              "      <td>No Obese</td>\n",
              "      <td>Absent</td>\n",
              "      <td>No HF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MPI003</td>\n",
              "      <td>530942</td>\n",
              "      <td>3</td>\n",
              "      <td>ST-Elevation Myocardial Infarction (STEMI)</td>\n",
              "      <td>No Arrhythmia</td>\n",
              "      <td>No</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>139</td>\n",
              "      <td>4.9</td>\n",
              "      <td>140</td>\n",
              "      <td>130</td>\n",
              "      <td>100</td>\n",
              "      <td>6.500</td>\n",
              "      <td>85</td>\n",
              "      <td>No Obese</td>\n",
              "      <td>Absent</td>\n",
              "      <td>No HF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MPI004</td>\n",
              "      <td>3414</td>\n",
              "      <td>4</td>\n",
              "      <td>ST-Elevation Myocardial Infarction (STEMI)</td>\n",
              "      <td>No Arrhythmia</td>\n",
              "      <td>No</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>141</td>\n",
              "      <td>5.4</td>\n",
              "      <td>130</td>\n",
              "      <td>135</td>\n",
              "      <td>120</td>\n",
              "      <td>0.001</td>\n",
              "      <td>66</td>\n",
              "      <td>No Obese</td>\n",
              "      <td>Absent</td>\n",
              "      <td>No HF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MPI005</td>\n",
              "      <td>777747</td>\n",
              "      <td>5</td>\n",
              "      <td>ST-Elevation Myocardial Infarction (STEMI)</td>\n",
              "      <td>No Arrhythmia</td>\n",
              "      <td>No</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>141</td>\n",
              "      <td>6.0</td>\n",
              "      <td>130</td>\n",
              "      <td>220</td>\n",
              "      <td>190</td>\n",
              "      <td>0.003</td>\n",
              "      <td>70</td>\n",
              "      <td>Obese</td>\n",
              "      <td>Absent</td>\n",
              "      <td>No HF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  StudyID    UHID  SN                 Acute Coronary Syndrome  (ACS)  \\\n",
              "0  MPI001  205179   1     ST-Elevation Myocardial Infarction (STEMI)   \n",
              "1  MPI002  311074   2     ST-Elevation Myocardial Infarction (STEMI)   \n",
              "2  MPI003  530942   3     ST-Elevation Myocardial Infarction (STEMI)   \n",
              "3  MPI004    3414   4     ST-Elevation Myocardial Infarction (STEMI)   \n",
              "4  MPI005  777747   5     ST-Elevation Myocardial Infarction (STEMI)   \n",
              "\n",
              "  Irregular Heartbeat (Arrhythmia) Bronchial Asthma (BA)  \\\n",
              "0                    No Arrhythmia                    No   \n",
              "1                    No Arrhythmia                    No   \n",
              "2                    No Arrhythmia                    No   \n",
              "3                    No Arrhythmia                    No   \n",
              "4                    No Arrhythmia                    No   \n",
              "\n",
              "  Coronary Artery Disease (CAD) Chest X-ray (CXR)  \\\n",
              "0                        Normal            Normal   \n",
              "1                        Normal            Normal   \n",
              "2                        Normal            Normal   \n",
              "3                        Normal            Normal   \n",
              "4                        Normal            Normal   \n",
              "\n",
              "  Dyslipidemia : Abnormal Cholesterol Levels (DL) Diabetes Mellitus (DM)  ...  \\\n",
              "0                                              No                     No  ...   \n",
              "1                                              No                     No  ...   \n",
              "2                                              No                     No  ...   \n",
              "3                                              No                    Yes  ...   \n",
              "4                                             Yes                     No  ...   \n",
              "\n",
              "  Sodium (mmol/L) (Na) Random Blood Sugar (mg/dL) (RBS)  \\\n",
              "0                  140                              4.9   \n",
              "1                  137                              6.5   \n",
              "2                  139                              4.9   \n",
              "3                  141                              5.4   \n",
              "4                  141                              6.0   \n",
              "\n",
              "  Systolic Blood Pressure (mmHg) (SBP)  Total Cholesterol (mg/dL) (TC)  \\\n",
              "0                                  180                             100   \n",
              "1                                  140                             110   \n",
              "2                                  140                             130   \n",
              "3                                  130                             135   \n",
              "4                                  130                             220   \n",
              "\n",
              "  Triglycerides (mg/dL) (TG)  Troponin I (TropI) Weight (kg)   Obisity  \\\n",
              "0                         95               0.001          60     Obese   \n",
              "1                         85               0.005          64  No Obese   \n",
              "2                        100               6.500          85  No Obese   \n",
              "3                        120               0.001          66  No Obese   \n",
              "4                        190               0.003          70     Obese   \n",
              "\n",
              "  Chest_pain Heart Failure (HF)  \n",
              "0     Absent              No HF  \n",
              "1     Absent              No HF  \n",
              "2     Absent              No HF  \n",
              "3     Absent              No HF  \n",
              "4     Absent              No HF  \n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"HF Data.csv\", encoding='ISO-8859-1')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TUCKUgoskVXU",
      "metadata": {
        "id": "TUCKUgoskVXU"
      },
      "source": [
        "### Generate a profiling report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2338ee87",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ydata-profiling in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (4.16.1)\n",
            "Requirement already satisfied: scipy<1.16,>=1.4.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<3.0,>1.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (2.0.3)\n",
            "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (3.7.5)\n",
            "Requirement already satisfied: pydantic>=2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (2.10.6)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (6.0.2)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (3.1.6)\n",
            "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.2,>=1.16.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (1.24.4)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (0.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.24.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (2.32.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (4.67.1)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (0.13.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (1.10)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (0.14.1)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (4.4.0)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (1.9.4)\n",
            "Requirement already satisfied: dacite>=1.8 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (1.9.2)\n",
            "Requirement already satisfied: numba<=0.61,>=0.56.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from ydata-profiling) (0.58.1)\n",
            "Requirement already satisfied: PyWavelets in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from imagehash==4.3.1->ydata-profiling) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (6.4.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from numba<=0.61,>=0.56.0->ydata-profiling) (0.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from numba<=0.61,>=0.56.0->ydata-profiling) (8.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2025.1.31)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (25.3.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (3.1)\n",
            "Requirement already satisfied: puremagic in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (1.28)\n",
            "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from importlib-metadata->numba<=0.61,>=0.56.0->ydata-profiling) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/HF/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib<=3.10,>=3.5->ydata-profiling) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the ydata-profiling package\n",
        "%pip install ydata-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705301ac",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "50bcd4ff-5547-46f6-8fad-611637fe0ab6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c58a563b20704ccba61bf8de25db7a98",
            "6352801f4f724fbfad5cc352ed993622",
            "9b0db360a13243d8bb2378cbc0a8e928",
            "d4ac432b3022482f9551c8dff03e6973",
            "35824ba707724c3181518a1de20bec51",
            "a0c0d078b574472f962c8b5f03638357",
            "7c3824a14edb4fdeaf09fe74676bfd61",
            "09cd13a302824fa3b378c5706011345e",
            "45605bbc649c45a2bd93cf0736d98bb9",
            "7bf254ed55c54ee2ba09ec7b22ef2a60",
            "5419cbdf47f243e5b30485d7a1efb3dc",
            "e3b4f810a6aa4100b89b6f65b1e781fd",
            "df9b6cecf4fa4c2e954d1fed3302d086",
            "1c5db7148fb442f8a1b3a43d1b4bc54e",
            "685602690c9e466daf96aaece7a46d17",
            "02afc956a2ea48768e804099ed0681b6",
            "1bfe2a7bac664ade9373bd938296eab8",
            "dce89f969e8f4d71b3868410d9f47912",
            "0797560977f14cc49cf9b8be89568692",
            "97b6361c1f6f4d8a860dcf58df2e8c99",
            "e6bbccaf520946a3bcdfddfa82e78410",
            "2690837e7395446f9e428e6139138628",
            "c62e5abc51b74e20aef880e64c74c3cd",
            "ee9658d8a8a2451db5de924cb8dc26a8",
            "ec51562a27004d61a78a459ae59f63c0",
            "9ddce267b7bc4b628b07ca707e1653ac",
            "91d1dbed6d0c48bc861d14070a4efd9e",
            "9be5934c597b4226b22bc72b75c44cc9",
            "05e3ac82673c49f39ae2fe9cc75c7b01",
            "2722e070b2954201bfbccddac85cf4e6",
            "e5c2c72ba4e34ebdb02a12ac28d88eb8",
            "f2ebfd2740754667bbaf2d97a5389ed5",
            "92a044381974455e9dec5e9b366b61e3"
          ]
        },
        "id": "50bcd4ff-5547-46f6-8fad-611637fe0ab6",
        "outputId": "2d24dac6-27d6-484d-90d2-5b19eccd95b2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ipywidgets'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m/opt/anaconda3/envs/HF/lib/python3.8/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/HF/lib/python3.8/site-packages/ydata_profiling/profile_report.py:548\u001b[0m, in \u001b[0;36mProfileReport._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_html_\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The ipython notebook widgets user interface gets called by the jupyter notebook.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_notebook_iframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/HF/lib/python3.8/site-packages/ydata_profiling/profile_report.py:521\u001b[0m, in \u001b[0;36mProfileReport.to_notebook_iframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Used to output the HTML representation to a Jupyter notebook.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03mWhen config.notebook.iframe.attribute is \"src\", this function creates a temporary HTML file\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03min `./tmp/profile_[hash].html` and returns an Iframe pointing to that contents.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    This constructions solves problems with conflicting stylesheets and navigation links.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    522\u001b[0m     get_notebook_iframe,\n\u001b[1;32m    523\u001b[0m )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# Ignore warning: https://github.com/ipython/ipython/pull/11350/files\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
            "File \u001b[0;32m/opt/anaconda3/envs/HF/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WidgetAlerts\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollapse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WidgetCollapse\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     WidgetContainer,\n\u001b[1;32m      5\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/HF/lib/python3.8/site-packages/ydata_profiling/report/presentation/flavours/widget/alerts.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, Button, widgets\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alerts\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpresentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflavours\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m templates\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate a profiling report\n",
        "from ydata_profiling import ProfileReport  # Import ProfileReport\n",
        "\n",
        "profile = ProfileReport(data, title=\"Dataset Profiling Report\", explorative=True)\n",
        "profile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1c3f2c-c62c-405b-bf5a-fefb9c374d61",
      "metadata": {
        "id": "5f1c3f2c-c62c-405b-bf5a-fefb9c374d61"
      },
      "source": [
        "### Drop unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "582dcbd8-d2ae-49eb-9bb7-19839bc95c0c",
      "metadata": {
        "id": "582dcbd8-d2ae-49eb-9bb7-19839bc95c0c"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "data =data.drop(columns=['StudyID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbd29ac-a698-43c3-bc2a-9db223b82eb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbd29ac-a698-43c3-bc2a-9db223b82eb1",
        "outputId": "60042a3a-2834-413a-f888-c9423763bf50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Age', 'Sex', 'BMI', 'NYHA', 'HR', 'HTN', 'DM', 'Smoker', 'DL', 'BA',\n",
              "       'RBS', 'HbA1C', 'Creatinine', 'Na', 'K', 'Cl', 'Hb', 'TropI', 'CXR',\n",
              "       'ECG', 'LVIDd', 'FS', 'LVIDs', 'LVEF', 'RWMA', 'LAV', 'MI', 'ACS',\n",
              "       'Wall', 'Thrombolysis', 'ICT', 'IRT', 'MR', 'EA', 'DT', 'MPI', 'RR',\n",
              "       'Chest_pain', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP', 'HF'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eeeaa16-9c62-4a9d-97dc-34c20f81f34d",
      "metadata": {
        "id": "6eeeaa16-9c62-4a9d-97dc-34c20f81f34d"
      },
      "source": [
        "## Summery of Statistical Numberical Colums before remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b54be43-c2f9-40bf-9f20-ffc5121a944e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "2b54be43-c2f9-40bf-9f20-ffc5121a944e",
        "outputId": "7aa2c46a-acd8-4fc0-a9dd-98069ad06bc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>500.0</td>\n",
              "      <td>55.530000</td>\n",
              "      <td>12.696121</td>\n",
              "      <td>18.00</td>\n",
              "      <td>47.000</td>\n",
              "      <td>56.000</td>\n",
              "      <td>65.000</td>\n",
              "      <td>95.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>25.378720</td>\n",
              "      <td>4.048717</td>\n",
              "      <td>12.26</td>\n",
              "      <td>22.815</td>\n",
              "      <td>24.800</td>\n",
              "      <td>27.550</td>\n",
              "      <td>48.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR</th>\n",
              "      <td>500.0</td>\n",
              "      <td>80.706000</td>\n",
              "      <td>14.923706</td>\n",
              "      <td>30.00</td>\n",
              "      <td>72.000</td>\n",
              "      <td>78.000</td>\n",
              "      <td>88.000</td>\n",
              "      <td>153.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBS</th>\n",
              "      <td>500.0</td>\n",
              "      <td>8.227780</td>\n",
              "      <td>3.536930</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.800</td>\n",
              "      <td>7.000</td>\n",
              "      <td>9.650</td>\n",
              "      <td>28.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HbA1C</th>\n",
              "      <td>500.0</td>\n",
              "      <td>6.274600</td>\n",
              "      <td>1.769757</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.300</td>\n",
              "      <td>5.600</td>\n",
              "      <td>7.125</td>\n",
              "      <td>13.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Creatinine</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.332320</td>\n",
              "      <td>1.278408</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.960</td>\n",
              "      <td>1.105</td>\n",
              "      <td>1.300</td>\n",
              "      <td>15.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na</th>\n",
              "      <td>500.0</td>\n",
              "      <td>138.470000</td>\n",
              "      <td>3.909433</td>\n",
              "      <td>123.00</td>\n",
              "      <td>136.000</td>\n",
              "      <td>138.000</td>\n",
              "      <td>141.000</td>\n",
              "      <td>149.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <td>500.0</td>\n",
              "      <td>3.915160</td>\n",
              "      <td>0.353988</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.700</td>\n",
              "      <td>3.900</td>\n",
              "      <td>4.100</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cl</th>\n",
              "      <td>500.0</td>\n",
              "      <td>101.608000</td>\n",
              "      <td>5.190010</td>\n",
              "      <td>90.00</td>\n",
              "      <td>99.000</td>\n",
              "      <td>103.000</td>\n",
              "      <td>105.000</td>\n",
              "      <td>110.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hb</th>\n",
              "      <td>500.0</td>\n",
              "      <td>12.463200</td>\n",
              "      <td>1.469055</td>\n",
              "      <td>7.80</td>\n",
              "      <td>11.300</td>\n",
              "      <td>12.300</td>\n",
              "      <td>13.500</td>\n",
              "      <td>16.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TropI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>11.965276</td>\n",
              "      <td>17.603010</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>6.100</td>\n",
              "      <td>13.750</td>\n",
              "      <td>126.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDd</th>\n",
              "      <td>500.0</td>\n",
              "      <td>48.796000</td>\n",
              "      <td>7.392407</td>\n",
              "      <td>21.00</td>\n",
              "      <td>44.000</td>\n",
              "      <td>48.000</td>\n",
              "      <td>53.000</td>\n",
              "      <td>78.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FS</th>\n",
              "      <td>500.0</td>\n",
              "      <td>26.134000</td>\n",
              "      <td>7.523913</td>\n",
              "      <td>9.00</td>\n",
              "      <td>20.000</td>\n",
              "      <td>25.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>63.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDs</th>\n",
              "      <td>500.0</td>\n",
              "      <td>35.830000</td>\n",
              "      <td>8.480149</td>\n",
              "      <td>16.00</td>\n",
              "      <td>29.000</td>\n",
              "      <td>34.500</td>\n",
              "      <td>41.000</td>\n",
              "      <td>71.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVEF</th>\n",
              "      <td>500.0</td>\n",
              "      <td>48.972000</td>\n",
              "      <td>11.804996</td>\n",
              "      <td>20.00</td>\n",
              "      <td>40.000</td>\n",
              "      <td>50.000</td>\n",
              "      <td>60.000</td>\n",
              "      <td>75.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAV</th>\n",
              "      <td>500.0</td>\n",
              "      <td>35.116000</td>\n",
              "      <td>9.103862</td>\n",
              "      <td>12.00</td>\n",
              "      <td>28.000</td>\n",
              "      <td>35.000</td>\n",
              "      <td>42.000</td>\n",
              "      <td>57.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>87.936000</td>\n",
              "      <td>17.313215</td>\n",
              "      <td>37.00</td>\n",
              "      <td>78.000</td>\n",
              "      <td>88.000</td>\n",
              "      <td>101.000</td>\n",
              "      <td>148.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IRT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>98.036000</td>\n",
              "      <td>20.311470</td>\n",
              "      <td>42.00</td>\n",
              "      <td>83.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>111.000</td>\n",
              "      <td>185.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EA</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.106180</td>\n",
              "      <td>0.616587</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.940</td>\n",
              "      <td>1.210</td>\n",
              "      <td>5.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>154.088000</td>\n",
              "      <td>42.800983</td>\n",
              "      <td>66.00</td>\n",
              "      <td>124.000</td>\n",
              "      <td>155.000</td>\n",
              "      <td>176.000</td>\n",
              "      <td>368.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MPI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>0.218860</td>\n",
              "      <td>0.175814</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.310</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RR</th>\n",
              "      <td>500.0</td>\n",
              "      <td>20.482000</td>\n",
              "      <td>3.277065</td>\n",
              "      <td>11.00</td>\n",
              "      <td>18.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>22.000</td>\n",
              "      <td>42.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TC</th>\n",
              "      <td>500.0</td>\n",
              "      <td>175.102000</td>\n",
              "      <td>46.698062</td>\n",
              "      <td>90.00</td>\n",
              "      <td>139.500</td>\n",
              "      <td>170.000</td>\n",
              "      <td>209.250</td>\n",
              "      <td>363.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDLc</th>\n",
              "      <td>500.0</td>\n",
              "      <td>113.420000</td>\n",
              "      <td>37.649310</td>\n",
              "      <td>35.00</td>\n",
              "      <td>87.000</td>\n",
              "      <td>106.000</td>\n",
              "      <td>140.000</td>\n",
              "      <td>260.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDLc</th>\n",
              "      <td>500.0</td>\n",
              "      <td>34.556000</td>\n",
              "      <td>6.143480</td>\n",
              "      <td>19.00</td>\n",
              "      <td>32.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>38.000</td>\n",
              "      <td>80.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TG</th>\n",
              "      <td>500.0</td>\n",
              "      <td>170.766000</td>\n",
              "      <td>100.103430</td>\n",
              "      <td>45.00</td>\n",
              "      <td>105.000</td>\n",
              "      <td>140.000</td>\n",
              "      <td>210.000</td>\n",
              "      <td>1032.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BNP</th>\n",
              "      <td>500.0</td>\n",
              "      <td>86.518000</td>\n",
              "      <td>205.683215</td>\n",
              "      <td>5.00</td>\n",
              "      <td>13.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>25.000</td>\n",
              "      <td>1184.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            count        mean         std     min      25%      50%      75%  \\\n",
              "Age         500.0   55.530000   12.696121   18.00   47.000   56.000   65.000   \n",
              "BMI         500.0   25.378720    4.048717   12.26   22.815   24.800   27.550   \n",
              "HR          500.0   80.706000   14.923706   30.00   72.000   78.000   88.000   \n",
              "RBS         500.0    8.227780    3.536930    4.00    5.800    7.000    9.650   \n",
              "HbA1C       500.0    6.274600    1.769757    0.00    5.300    5.600    7.125   \n",
              "Creatinine  500.0    1.332320    1.278408    0.50    0.960    1.105    1.300   \n",
              "Na          500.0  138.470000    3.909433  123.00  136.000  138.000  141.000   \n",
              "K           500.0    3.915160    0.353988    3.00    3.700    3.900    4.100   \n",
              "Cl          500.0  101.608000    5.190010   90.00   99.000  103.000  105.000   \n",
              "Hb          500.0   12.463200    1.469055    7.80   11.300   12.300   13.500   \n",
              "TropI       500.0   11.965276   17.603010    0.00    0.005    6.100   13.750   \n",
              "LVIDd       500.0   48.796000    7.392407   21.00   44.000   48.000   53.000   \n",
              "FS          500.0   26.134000    7.523913    9.00   20.000   25.000   32.000   \n",
              "LVIDs       500.0   35.830000    8.480149   16.00   29.000   34.500   41.000   \n",
              "LVEF        500.0   48.972000   11.804996   20.00   40.000   50.000   60.000   \n",
              "LAV         500.0   35.116000    9.103862   12.00   28.000   35.000   42.000   \n",
              "ICT         500.0   87.936000   17.313215   37.00   78.000   88.000  101.000   \n",
              "IRT         500.0   98.036000   20.311470   42.00   83.000   97.000  111.000   \n",
              "EA          500.0    1.106180    0.616587    0.00    0.780    0.940    1.210   \n",
              "DT          500.0  154.088000   42.800983   66.00  124.000  155.000  176.000   \n",
              "MPI         500.0    0.218860    0.175814    0.01    0.080    0.180    0.310   \n",
              "RR          500.0   20.482000    3.277065   11.00   18.000   20.000   22.000   \n",
              "TC          500.0  175.102000   46.698062   90.00  139.500  170.000  209.250   \n",
              "LDLc        500.0  113.420000   37.649310   35.00   87.000  106.000  140.000   \n",
              "HDLc        500.0   34.556000    6.143480   19.00   32.000   34.000   38.000   \n",
              "TG          500.0  170.766000  100.103430   45.00  105.000  140.000  210.000   \n",
              "BNP         500.0   86.518000  205.683215    5.00   13.000   20.000   25.000   \n",
              "\n",
              "                max  \n",
              "Age           95.00  \n",
              "BMI           48.89  \n",
              "HR           153.00  \n",
              "RBS           28.70  \n",
              "HbA1C         13.40  \n",
              "Creatinine    15.08  \n",
              "Na           149.00  \n",
              "K              6.00  \n",
              "Cl           110.00  \n",
              "Hb            16.70  \n",
              "TropI        126.00  \n",
              "LVIDd         78.00  \n",
              "FS            63.00  \n",
              "LVIDs         71.00  \n",
              "LVEF          75.00  \n",
              "LAV           57.00  \n",
              "ICT          148.00  \n",
              "IRT          185.00  \n",
              "EA             5.30  \n",
              "DT           368.00  \n",
              "MPI            1.02  \n",
              "RR            42.00  \n",
              "TC           363.00  \n",
              "LDLc         260.00  \n",
              "HDLc          80.00  \n",
              "TG          1032.00  \n",
              "BNP         1184.00  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe(include=[np.number]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf6e82c-65c0-46d8-97a9-cc12ab9dbeef",
      "metadata": {
        "id": "8cf6e82c-65c0-46d8-97a9-cc12ab9dbeef"
      },
      "source": [
        "### Cheak data Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34420cd2-0343-402e-84b6-7f83fae52298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34420cd2-0343-402e-84b6-7f83fae52298",
        "outputId": "518cd352-80f7-4991-f084-fed9fa9d518e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 44)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e2c0ea-29d5-4009-8fb5-bab7c6833794",
      "metadata": {
        "id": "30e2c0ea-29d5-4009-8fb5-bab7c6833794"
      },
      "source": [
        "## Cheak missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283e4c4f-735d-4fdc-9269-a1e005b68e94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "283e4c4f-735d-4fdc-9269-a1e005b68e94",
        "outputId": "5b101914-f7b1-4100-dd2d-5f71aaa9aaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values in Each Column:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Total Missing Values in the Dataset: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Display columns with missing values\n",
        "print(\"Missing Values in Each Column:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Display the total number of missing values\n",
        "total_missing = data.isnull().sum().sum()\n",
        "print(f\"\\nTotal Missing Values in the Dataset: {total_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7c93ee-b22c-47d7-ab1d-acc24ccfc570",
      "metadata": {
        "id": "6c7c93ee-b22c-47d7-ab1d-acc24ccfc570"
      },
      "source": [
        "## Cheaking duplicate columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53730f8c-b35c-438d-b9d9-b6480b013826",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53730f8c-b35c-438d-b9d9-b6480b013826",
        "outputId": "152dab61-71b6-4096-8d1a-d3097ac0515f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No duplicate columns found.\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate columns\n",
        "duplicate_columns = data.columns[data.columns.duplicated()].unique()\n",
        "\n",
        "# Display the duplicate columns (if any)\n",
        "if len(duplicate_columns) > 0:\n",
        "    print(f\"Duplicate columns found: {duplicate_columns}\")\n",
        "else:\n",
        "    print(\"No duplicate columns found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b11e3236-bb79-4e9b-9890-2e3b4fa9ec26",
      "metadata": {
        "id": "b11e3236-bb79-4e9b-9890-2e3b4fa9ec26"
      },
      "source": [
        "## Check for duplicate rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbd0c87-a249-4c86-ab97-925759714d1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbbd0c87-a249-4c86-ab97-925759714d1d",
        "outputId": "2bb5d3eb-7620-40bd-e127-50586afd7cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No duplicate rows found.\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate rows\n",
        "duplicate_rows = data[data.duplicated()]\n",
        "\n",
        "# Display the duplicate rows (if any)\n",
        "if not duplicate_rows.empty:\n",
        "    print(\"Duplicate rows found:\")\n",
        "    print(duplicate_rows)\n",
        "else:\n",
        "    print(\"No duplicate rows found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c36ef1e-8d55-4721-ba48-67ae90e45ba3",
      "metadata": {
        "id": "5c36ef1e-8d55-4721-ba48-67ae90e45ba3"
      },
      "source": [
        "### Outliners decetion and Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a07a60-f11a-49eb-a9a9-efd513bbfdeb",
      "metadata": {
        "id": "97a07a60-f11a-49eb-a9a9-efd513bbfdeb"
      },
      "source": [
        "Which Method is Best for Heart Disease Prediction?\n",
        "\n",
        "If the dataset is small and structured: Use IQR or Z-Score.\n",
        "\n",
        "If the dataset has high-dimensional features: Use Isolation Forest or LOF.\n",
        "\n",
        "If there are non-linear patterns: Use DBSCAN.\n",
        "\n",
        " A common approach in medical datasets is to log transform certain features (e.g., glucose levels, blood pressure) that have highly skewed distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8d34ab-5679-4bb2-8da6-ac6fd9e2e212",
      "metadata": {
        "id": "5c8d34ab-5679-4bb2-8da6-ac6fd9e2e212"
      },
      "source": [
        "#### Plot Oulters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74456bba-b04c-433e-a04c-9a5451fc37f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "74456bba-b04c-433e-a04c-9a5451fc37f5",
        "outputId": "dd753683-8cba-499d-85d0-3cbf38a0f106",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Set up the plotting grid\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "fig, axes = plt.subplots(nrows=len(num_cols), ncols=2, figsize=(10, len(num_cols)*5))\n",
        "\n",
        "# Loop through numeric columns and plot histograms and scatter plots\n",
        "for i, col in enumerate(num_cols):\n",
        "    # Histogram\n",
        "    sns.histplot(data[col], kde=True, ax=axes[i, 0])\n",
        "    axes[i, 0].set_title(f'Histogram of {col}')\n",
        "\n",
        "    # Detect outliers using IQR method\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "\n",
        "    # Scatter plot with outliers in a different color\n",
        "    sns.scatterplot(x=data.index, y=data[col], ax=axes[i, 1], color=['skyblue'])  # Normal points\n",
        "    sns.scatterplot(x=outliers.index, y=outliers[col], ax=axes[i, 1], color='red')  # Outliers in red\n",
        "    axes[i, 1].set_title(f'Scatter Plot of {col} with Outliers')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7rOFCIX6Rt3",
      "metadata": {
        "id": "d7rOFCIX6Rt3"
      },
      "source": [
        "## Classification based on Skewness and Normality Test:\n",
        "Normal Distribution: If the skewness is near 0 and the p-value from the normality test is greater than 0.05, the feature is classified as normally distributed.\n",
        "\n",
        "Right-skewed: Features with a positive skewness greater than 0.5 are considered right-skewed.\n",
        "\n",
        "Left-skewed: Features with a negative skewness less than -0.5 are considered left-skewed.\n",
        "\n",
        "Non-normal: Features that fail the normality test (p_value < 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L4XLHkzRjMMI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4XLHkzRjMMI",
        "outputId": "d7a5cdaa-5240-49d9-a636-9b1363a6c103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Distributed Features:\n",
            "['Age', 'ICT']\n",
            "\n",
            "Right Skewed Features:\n",
            "['BMI', 'HR', 'RBS', 'HbA1C', 'Creatinine', 'K', 'TropI', 'LVIDs', 'EA', 'DT', 'MPI', 'RR', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP']\n",
            "\n",
            "Left Skewed Features:\n",
            "['Cl']\n",
            "\n",
            "Non-Normal Distributed Features (failed normality test):\n",
            "['BMI', 'HR', 'RBS', 'HbA1C', 'Creatinine', 'Na', 'K', 'Cl', 'Hb', 'TropI', 'LVIDd', 'FS', 'LVIDs', 'LVEF', 'LAV', 'IRT', 'EA', 'DT', 'MPI', 'RR', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, normaltest\n",
        "\n",
        "# Assuming `data` is your dataset (e.g., a pandas DataFrame)\n",
        "\n",
        "# Initialize empty lists to store the classification results\n",
        "normal_dist = []\n",
        "right_skewed = []\n",
        "left_skewed = []\n",
        "non_normal_dist = []  # List to store non-normal features\n",
        "\n",
        "# Iterate over each numeric column in the dataset\n",
        "for column in data.select_dtypes(include=[np.number]).columns:\n",
        "    # Calculate skewness\n",
        "    feature_skewness = skew(data[column].dropna())  # Drop NaN values before calculation\n",
        "\n",
        "    # Check for normality using D'Agostino's K-squared test (normality test)\n",
        "    _, p_value = normaltest(data[column].dropna())  # p_value < 0.05 means the data is not normal\n",
        "\n",
        "    if abs(feature_skewness) < 0.5 and p_value > 0.05:\n",
        "        # If skewness is close to 0 and data passes the normality test\n",
        "        normal_dist.append(column)\n",
        "    elif feature_skewness > 0.5:\n",
        "        # If skewness is positive (right skewed)\n",
        "        right_skewed.append(column)\n",
        "    elif feature_skewness < -0.5:\n",
        "        # If skewness is negative (left skewed)\n",
        "        left_skewed.append(column)\n",
        "\n",
        "    # Classify as non-normal if the p-value is < 0.05 (fails normality test)\n",
        "    if p_value < 0.05:\n",
        "        non_normal_dist.append(column)\n",
        "\n",
        "# Print the results\n",
        "print(\"Normal Distributed Features:\")\n",
        "print(normal_dist)\n",
        "\n",
        "print(\"\\nRight Skewed Features:\")\n",
        "print(right_skewed)\n",
        "\n",
        "print(\"\\nLeft Skewed Features:\")\n",
        "print(left_skewed)\n",
        "\n",
        "print(\"\\nNon-Normal Distributed Features (failed normality test):\")\n",
        "print(non_normal_dist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mau_i2-i6AgF",
      "metadata": {
        "id": "Mau_i2-i6AgF"
      },
      "source": [
        " ### Transformations and Outliers:\n",
        "\n",
        "Log Transformation: Reduces the impact of high right-skewed outliers.\n",
        "\n",
        "Square Root Transformation: Helps with moderate skewness.\n",
        "\n",
        "Box-Cox Transformation: Transforms data into a more normal distribution, which is helpful for handling both positive and negative skewness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O9H1StBFd5j1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9H1StBFd5j1",
        "outputId": "033eaac0-f880-4165-ce86-2336cdb85325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Transformation:\n",
            "              Age         BMI          HR        RBS       HbA1C  Creatinine  \\\n",
            "count  500.000000  500.000000  500.000000  500.00000  500.000000  500.000000   \n",
            "mean    55.530000   25.378720   80.706000    8.22778    6.274600    1.332320   \n",
            "std     12.696121    4.048717   14.923706    3.53693    1.769757    1.278408   \n",
            "min     18.000000   12.260000   30.000000    4.00000    0.000000    0.500000   \n",
            "25%     47.000000   22.815000   72.000000    5.80000    5.300000    0.960000   \n",
            "50%     56.000000   24.800000   78.000000    7.00000    5.600000    1.105000   \n",
            "75%     65.000000   27.550000   88.000000    9.65000    7.125000    1.300000   \n",
            "max     95.000000   48.890000  153.000000   28.70000   13.400000   15.080000   \n",
            "\n",
            "               Na           K         Cl          Hb  ...        IRT  \\\n",
            "count  500.000000  500.000000  500.00000  500.000000  ...  500.00000   \n",
            "mean   138.470000    3.915160  101.60800   12.463200  ...   98.03600   \n",
            "std      3.909433    0.353988    5.19001    1.469055  ...   20.31147   \n",
            "min    123.000000    3.000000   90.00000    7.800000  ...   42.00000   \n",
            "25%    136.000000    3.700000   99.00000   11.300000  ...   83.00000   \n",
            "50%    138.000000    3.900000  103.00000   12.300000  ...   97.00000   \n",
            "75%    141.000000    4.100000  105.00000   13.500000  ...  111.00000   \n",
            "max    149.000000    6.000000  110.00000   16.700000  ...  185.00000   \n",
            "\n",
            "               EA          DT         MPI          RR          TC       LDLc  \\\n",
            "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.00000   \n",
            "mean     1.106180  154.088000    0.218860   20.482000  175.102000  113.42000   \n",
            "std      0.616587   42.800983    0.175814    3.277065   46.698062   37.64931   \n",
            "min      0.000000   66.000000    0.010000   11.000000   90.000000   35.00000   \n",
            "25%      0.780000  124.000000    0.080000   18.000000  139.500000   87.00000   \n",
            "50%      0.940000  155.000000    0.180000   20.000000  170.000000  106.00000   \n",
            "75%      1.210000  176.000000    0.310000   22.000000  209.250000  140.00000   \n",
            "max      5.300000  368.000000    1.020000   42.000000  363.000000  260.00000   \n",
            "\n",
            "            HDLc          TG          BNP  \n",
            "count  500.00000   500.00000   500.000000  \n",
            "mean    34.55600   170.76600    86.518000  \n",
            "std      6.14348   100.10343   205.683215  \n",
            "min     19.00000    45.00000     5.000000  \n",
            "25%     32.00000   105.00000    13.000000  \n",
            "50%     34.00000   140.00000    20.000000  \n",
            "75%     38.00000   210.00000    25.000000  \n",
            "max     80.00000  1032.00000  1184.000000  \n",
            "\n",
            "[8 rows x 27 columns]\n",
            "\n",
            "Outliers Before Transformation:\n",
            "{'Age': 2, 'BMI': 17, 'HR': 22, 'RBS': 23, 'HbA1C': 33, 'Creatinine': 32, 'Na': 21, 'K': 23, 'Cl': 0, 'Hb': 2, 'TropI': 55, 'LVIDd': 13, 'FS': 1, 'LVIDs': 5, 'LVEF': 0, 'LAV': 0, 'ICT': 5, 'IRT': 4, 'EA': 44, 'DT': 8, 'MPI': 12, 'RR': 8, 'TC': 3, 'LDLc': 5, 'HDLc': 22, 'TG': 22, 'BNP': 70}\n",
            "\n",
            "After Transformation:\n",
            "              Age         BMI          HR         RBS       HbA1C  Creatinine  \\\n",
            "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
            "mean    55.530000    3.261360    4.387170    2.167029    6.274600    0.795121   \n",
            "std     12.696121    0.148763    0.178348    0.314227    1.769757    0.257166   \n",
            "min     18.000000    2.584752    3.433987    1.609438    0.000000    0.405465   \n",
            "25%     47.000000    3.170315    4.290459    1.916923    5.300000    0.672944   \n",
            "50%     56.000000    3.250374    4.369448    2.079442    5.600000    0.744313   \n",
            "75%     65.000000    3.351657    4.488636    2.365527    7.125000    0.832909   \n",
            "max     95.000000    3.909821    5.036953    3.391147   13.400000    2.777576   \n",
            "\n",
            "               Na           K          Cl          Hb  ...          MR  \\\n",
            "count  500.000000  500.000000  500.000000  500.000000  ...  500.000000   \n",
            "mean     1.135711    0.514178   10.126247    6.043807  ...    1.023585   \n",
            "std      0.000384    0.003662    0.259355    0.492228  ...    0.238851   \n",
            "min      1.134021    0.501159    9.539392    4.356774  ...    0.693147   \n",
            "25%      1.135474    0.512052   10.000000    5.658422  ...    0.693147   \n",
            "50%      1.135675    0.514380   10.198039    6.000356  ...    1.098612   \n",
            "75%      1.135966    0.516452   10.295630    6.396693  ...    1.098612   \n",
            "max      1.136689    0.528436   10.535654    7.390996  ...    1.609438   \n",
            "\n",
            "               EA          DT         MPI          RR          TC        LDLc  \\\n",
            "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
            "mean     1.106180    9.068280    0.188548    2.029354    5.136789    4.685328   \n",
            "std      0.616587    0.813437    0.133866    0.061172    0.261984    0.334704   \n",
            "min      0.000000    6.864492    0.009950    1.773586    4.510860    3.583519   \n",
            "25%      0.780000    8.525956    0.076961    1.983667    4.945188    4.477337   \n",
            "50%      0.940000    9.172391    0.165514    2.025843    5.141664    4.672785   \n",
            "75%      1.210000    9.555036    0.270027    2.063136    5.348295    4.948760   \n",
            "max      5.300000   12.001104    0.703098    2.294746    5.897154    5.564520   \n",
            "\n",
            "             HDLc          TG         BNP  \n",
            "count  500.000000  500.000000  500.000000  \n",
            "mean     3.557207    5.019837    6.645095  \n",
            "std      0.165604    0.482527    6.591480  \n",
            "min      2.995732    3.828641    2.449490  \n",
            "25%      3.496508    4.663439    3.741657  \n",
            "50%      3.555348    4.948760    4.582576  \n",
            "75%      3.663562    5.351858    5.099020  \n",
            "max      4.394449    6.940222   34.423829  \n",
            "\n",
            "[8 rows x 28 columns]\n",
            "\n",
            "Outliers After Transformation:\n",
            "{'Age': 2, 'BMI': 10, 'HR': 21, 'RBS': 7, 'HbA1C': 33, 'Creatinine': 29, 'Na': 9, 'K': 18, 'Cl': 52, 'Hb': 2, 'TropI': 55, 'LVIDd': 12, 'FS': 1, 'LVIDs': 2, 'LVEF': 0, 'LAV': 0, 'ICT': 5, 'IRT': 5, 'MR': 0, 'EA': 44, 'DT': 7, 'MPI': 9, 'RR': 7, 'TC': 0, 'LDLc': 2, 'HDLc': 28, 'TG': 1, 'BNP': 70}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Assuming `data` is your DataFrame and you already have skewed features identified\n",
        "\n",
        "# Create a copy of the original data to keep track of changes\n",
        "data_transformed = data.copy()\n",
        "\n",
        "# Function to detect outliers using IQR method\n",
        "\n",
        "def detect_outliers_iqr(df):\n",
        "    outliers = {}\n",
        "    # Select only numerical columns for outlier detection\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    for column in numeric_cols:  # Iterate through numerical columns\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        outliers[column] = ((df[column] < lower_bound) | (df[column] > upper_bound)).sum()\n",
        "    return outliers\n",
        "\n",
        "# Print before transformation\n",
        "print(\"Before Transformation:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Check outliers before transformation\n",
        "outliers_before = detect_outliers_iqr(data)\n",
        "print(\"\\nOutliers Before Transformation:\")\n",
        "print(outliers_before)\n",
        "\n",
        "# 1. Apply Log Transformation to Right-Skewed Features\n",
        "right_skewed = ['BMI', 'HR', 'RBS', 'Creatinine', 'K', 'LVIDs', 'MR', 'MPI', 'RR', 'TC', 'LDLc', 'HDLc', 'TG']\n",
        "\n",
        "for column in right_skewed:\n",
        "    data[column] = pd.to_numeric(data[column], errors='coerce')  # Ensure numeric values\n",
        "    if data[column].notna().all() and (data[column] > 0).all():\n",
        "        data_transformed[column] = np.log(data[column] + 1)\n",
        "\n",
        "# 2. Apply Square Root or Cube Root Transformation to Moderately Skewed Features (Optional)\n",
        "moderately_skewed = ['HbA1C', 'Cl', 'TropI', 'BNP']  # Example for left-skewed features\n",
        "\n",
        "for column in moderately_skewed:\n",
        "    if (data[column] > 0).all():  # Ensure no negative or zero values\n",
        "        data_transformed[column] = np.sqrt(data[column] + 1)  # Square root transformation for moderate skewness\n",
        "\n",
        "# 3. Apply Box-Cox Transformation to Non-Normal Distributed Features\n",
        "# Box-Cox works best when the data is strictly positive\n",
        "non_normal_dist = [ 'Na','K','Hb','LVIDd','FS','LVEF','LAV','IRT','EA','DT','RR']\n",
        "\n",
        "for column in non_normal_dist:\n",
        "    if (data[column] > 0).all():  # Apply only if data is strictly positive\n",
        "        data_transformed[column], _ = stats.boxcox(data[column] + 1)  # Add 1 to avoid log(0)\n",
        "\n",
        "# Print after transformation\n",
        "print(\"\\nAfter Transformation:\")\n",
        "print(data_transformed.describe())\n",
        "\n",
        "# Check outliers after transformation\n",
        "outliers_after = detect_outliers_iqr(data_transformed)\n",
        "print(\"\\nOutliers After Transformation:\")\n",
        "print(outliers_after)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ftZT_L6j7vxG",
      "metadata": {
        "id": "ftZT_L6j7vxG"
      },
      "source": [
        "Distribution of Brfore and After Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OYkB76NdpftN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OYkB76NdpftN",
        "outputId": "35680beb-439a-4d0d-ea0f-965dcaf2ae90"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loop over each numeric feature to plot\n",
        "for feature in data.select_dtypes(include=[np.number]).columns:\n",
        "    # Create a figure with 2 subplots (side by side)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Plot Before Transformation\n",
        "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, this is the first subplot\n",
        "    sns.histplot(data[feature], kde=True)\n",
        "    plt.title(f'Distribution of {feature} Before Transformation')\n",
        "\n",
        "    # Plot After Transformation\n",
        "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, this is the second subplot\n",
        "    sns.histplot(data_transformed[feature], kde=True)\n",
        "    plt.title(f'Distribution of {feature} After Log Transformation')\n",
        "\n",
        "    # Show both plots\n",
        "    plt.tight_layout()  # Adjust layout to avoid overlap\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VEXXwnoNs2kC",
      "metadata": {
        "id": "VEXXwnoNs2kC"
      },
      "source": [
        "Function to apply capping (winsorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxAoJTOas3Xy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAoJTOas3Xy",
        "outputId": "93a63c93-f0c5-4436-8bfc-4225c4ff66fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Outliers After Capping:\n",
            "{'Age': 0, 'BMI': 8, 'HR': 21, 'RBS': 7, 'HbA1C': 32, 'Creatinine': 28, 'Na': 9, 'K': 18, 'Cl': 52, 'Hb': 0, 'TropI': 55, 'LVIDd': 8, 'FS': 0, 'LVIDs': 0, 'LVEF': 0, 'LAV': 0, 'ICT': 0, 'IRT': 0, 'MR': 0, 'EA': 43, 'DT': 6, 'MPI': 9, 'RR': 0, 'TC': 0, 'LDLc': 0, 'HDLc': 28, 'TG': 0, 'BNP': 70}\n"
          ]
        }
      ],
      "source": [
        "# Function to apply capping (winsorization)\n",
        "def cap_outliers(df, columns, lower_percentile=0.01, upper_percentile=0.99):\n",
        "    for column in columns:\n",
        "        lower_limit = df[column].quantile(lower_percentile)\n",
        "        upper_limit = df[column].quantile(upper_percentile)\n",
        "        df[column] = np.where(df[column] < lower_limit, lower_limit, df[column])\n",
        "        df[column] = np.where(df[column] > upper_limit, upper_limit, df[column])\n",
        "    return df\n",
        "\n",
        "# Apply capping to all numerical columns\n",
        "numeric_cols = data_transformed.select_dtypes(include=[np.number]).columns\n",
        "data_transformed = cap_outliers(data_transformed, numeric_cols)\n",
        "\n",
        "# Check outliers after capping\n",
        "outliers_after_capping = detect_outliers_iqr(data_transformed)\n",
        "print(\"\\nOutliers After Capping:\")\n",
        "print(outliers_after_capping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7ff499-baba-48bd-8660-e263ed4b545d",
      "metadata": {
        "id": "ab7ff499-baba-48bd-8660-e263ed4b545d"
      },
      "source": [
        "## Descriptive Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0549577-09bc-491a-9988-3bd9772a38c9",
      "metadata": {
        "id": "a0549577-09bc-491a-9988-3bd9772a38c9"
      },
      "source": [
        "### Summery of Statistical Numberical Colums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7602c1b-bcd8-48cf-ae61-a7986bb96b44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "e7602c1b-bcd8-48cf-ae61-a7986bb96b44",
        "outputId": "52ea5ab6-1887-41fd-8a27-6661155f5b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>500.0</td>\n",
              "      <td>55.530000</td>\n",
              "      <td>12.696121</td>\n",
              "      <td>18.00</td>\n",
              "      <td>47.000</td>\n",
              "      <td>56.000</td>\n",
              "      <td>65.000</td>\n",
              "      <td>95.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>25.378720</td>\n",
              "      <td>4.048717</td>\n",
              "      <td>12.26</td>\n",
              "      <td>22.815</td>\n",
              "      <td>24.800</td>\n",
              "      <td>27.550</td>\n",
              "      <td>48.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR</th>\n",
              "      <td>500.0</td>\n",
              "      <td>80.706000</td>\n",
              "      <td>14.923706</td>\n",
              "      <td>30.00</td>\n",
              "      <td>72.000</td>\n",
              "      <td>78.000</td>\n",
              "      <td>88.000</td>\n",
              "      <td>153.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBS</th>\n",
              "      <td>500.0</td>\n",
              "      <td>8.227780</td>\n",
              "      <td>3.536930</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.800</td>\n",
              "      <td>7.000</td>\n",
              "      <td>9.650</td>\n",
              "      <td>28.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HbA1C</th>\n",
              "      <td>500.0</td>\n",
              "      <td>6.274600</td>\n",
              "      <td>1.769757</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.300</td>\n",
              "      <td>5.600</td>\n",
              "      <td>7.125</td>\n",
              "      <td>13.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Creatinine</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.332320</td>\n",
              "      <td>1.278408</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.960</td>\n",
              "      <td>1.105</td>\n",
              "      <td>1.300</td>\n",
              "      <td>15.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na</th>\n",
              "      <td>500.0</td>\n",
              "      <td>138.470000</td>\n",
              "      <td>3.909433</td>\n",
              "      <td>123.00</td>\n",
              "      <td>136.000</td>\n",
              "      <td>138.000</td>\n",
              "      <td>141.000</td>\n",
              "      <td>149.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <td>500.0</td>\n",
              "      <td>3.915160</td>\n",
              "      <td>0.353988</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.700</td>\n",
              "      <td>3.900</td>\n",
              "      <td>4.100</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cl</th>\n",
              "      <td>500.0</td>\n",
              "      <td>101.608000</td>\n",
              "      <td>5.190010</td>\n",
              "      <td>90.00</td>\n",
              "      <td>99.000</td>\n",
              "      <td>103.000</td>\n",
              "      <td>105.000</td>\n",
              "      <td>110.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hb</th>\n",
              "      <td>500.0</td>\n",
              "      <td>12.463200</td>\n",
              "      <td>1.469055</td>\n",
              "      <td>7.80</td>\n",
              "      <td>11.300</td>\n",
              "      <td>12.300</td>\n",
              "      <td>13.500</td>\n",
              "      <td>16.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TropI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>11.965276</td>\n",
              "      <td>17.603010</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>6.100</td>\n",
              "      <td>13.750</td>\n",
              "      <td>126.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDd</th>\n",
              "      <td>500.0</td>\n",
              "      <td>48.796000</td>\n",
              "      <td>7.392407</td>\n",
              "      <td>21.00</td>\n",
              "      <td>44.000</td>\n",
              "      <td>48.000</td>\n",
              "      <td>53.000</td>\n",
              "      <td>78.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FS</th>\n",
              "      <td>500.0</td>\n",
              "      <td>26.134000</td>\n",
              "      <td>7.523913</td>\n",
              "      <td>9.00</td>\n",
              "      <td>20.000</td>\n",
              "      <td>25.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>63.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDs</th>\n",
              "      <td>500.0</td>\n",
              "      <td>35.830000</td>\n",
              "      <td>8.480149</td>\n",
              "      <td>16.00</td>\n",
              "      <td>29.000</td>\n",
              "      <td>34.500</td>\n",
              "      <td>41.000</td>\n",
              "      <td>71.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVEF</th>\n",
              "      <td>500.0</td>\n",
              "      <td>48.972000</td>\n",
              "      <td>11.804996</td>\n",
              "      <td>20.00</td>\n",
              "      <td>40.000</td>\n",
              "      <td>50.000</td>\n",
              "      <td>60.000</td>\n",
              "      <td>75.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAV</th>\n",
              "      <td>500.0</td>\n",
              "      <td>35.116000</td>\n",
              "      <td>9.103862</td>\n",
              "      <td>12.00</td>\n",
              "      <td>28.000</td>\n",
              "      <td>35.000</td>\n",
              "      <td>42.000</td>\n",
              "      <td>57.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>87.936000</td>\n",
              "      <td>17.313215</td>\n",
              "      <td>37.00</td>\n",
              "      <td>78.000</td>\n",
              "      <td>88.000</td>\n",
              "      <td>101.000</td>\n",
              "      <td>148.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IRT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>98.036000</td>\n",
              "      <td>20.311470</td>\n",
              "      <td>42.00</td>\n",
              "      <td>83.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>111.000</td>\n",
              "      <td>185.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MR</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.864000</td>\n",
              "      <td>0.700346</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EA</th>\n",
              "      <td>500.0</td>\n",
              "      <td>1.106180</td>\n",
              "      <td>0.616587</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.940</td>\n",
              "      <td>1.210</td>\n",
              "      <td>5.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>500.0</td>\n",
              "      <td>154.088000</td>\n",
              "      <td>42.800983</td>\n",
              "      <td>66.00</td>\n",
              "      <td>124.000</td>\n",
              "      <td>155.000</td>\n",
              "      <td>176.000</td>\n",
              "      <td>368.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MPI</th>\n",
              "      <td>500.0</td>\n",
              "      <td>0.218860</td>\n",
              "      <td>0.175814</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.310</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RR</th>\n",
              "      <td>500.0</td>\n",
              "      <td>20.482000</td>\n",
              "      <td>3.277065</td>\n",
              "      <td>11.00</td>\n",
              "      <td>18.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>22.000</td>\n",
              "      <td>42.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TC</th>\n",
              "      <td>500.0</td>\n",
              "      <td>175.102000</td>\n",
              "      <td>46.698062</td>\n",
              "      <td>90.00</td>\n",
              "      <td>139.500</td>\n",
              "      <td>170.000</td>\n",
              "      <td>209.250</td>\n",
              "      <td>363.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDLc</th>\n",
              "      <td>500.0</td>\n",
              "      <td>113.420000</td>\n",
              "      <td>37.649310</td>\n",
              "      <td>35.00</td>\n",
              "      <td>87.000</td>\n",
              "      <td>106.000</td>\n",
              "      <td>140.000</td>\n",
              "      <td>260.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDLc</th>\n",
              "      <td>500.0</td>\n",
              "      <td>34.556000</td>\n",
              "      <td>6.143480</td>\n",
              "      <td>19.00</td>\n",
              "      <td>32.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>38.000</td>\n",
              "      <td>80.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TG</th>\n",
              "      <td>500.0</td>\n",
              "      <td>170.766000</td>\n",
              "      <td>100.103430</td>\n",
              "      <td>45.00</td>\n",
              "      <td>105.000</td>\n",
              "      <td>140.000</td>\n",
              "      <td>210.000</td>\n",
              "      <td>1032.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BNP</th>\n",
              "      <td>500.0</td>\n",
              "      <td>86.518000</td>\n",
              "      <td>205.683215</td>\n",
              "      <td>5.00</td>\n",
              "      <td>13.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>25.000</td>\n",
              "      <td>1184.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            count        mean         std     min      25%      50%      75%  \\\n",
              "Age         500.0   55.530000   12.696121   18.00   47.000   56.000   65.000   \n",
              "BMI         500.0   25.378720    4.048717   12.26   22.815   24.800   27.550   \n",
              "HR          500.0   80.706000   14.923706   30.00   72.000   78.000   88.000   \n",
              "RBS         500.0    8.227780    3.536930    4.00    5.800    7.000    9.650   \n",
              "HbA1C       500.0    6.274600    1.769757    0.00    5.300    5.600    7.125   \n",
              "Creatinine  500.0    1.332320    1.278408    0.50    0.960    1.105    1.300   \n",
              "Na          500.0  138.470000    3.909433  123.00  136.000  138.000  141.000   \n",
              "K           500.0    3.915160    0.353988    3.00    3.700    3.900    4.100   \n",
              "Cl          500.0  101.608000    5.190010   90.00   99.000  103.000  105.000   \n",
              "Hb          500.0   12.463200    1.469055    7.80   11.300   12.300   13.500   \n",
              "TropI       500.0   11.965276   17.603010    0.00    0.005    6.100   13.750   \n",
              "LVIDd       500.0   48.796000    7.392407   21.00   44.000   48.000   53.000   \n",
              "FS          500.0   26.134000    7.523913    9.00   20.000   25.000   32.000   \n",
              "LVIDs       500.0   35.830000    8.480149   16.00   29.000   34.500   41.000   \n",
              "LVEF        500.0   48.972000   11.804996   20.00   40.000   50.000   60.000   \n",
              "LAV         500.0   35.116000    9.103862   12.00   28.000   35.000   42.000   \n",
              "ICT         500.0   87.936000   17.313215   37.00   78.000   88.000  101.000   \n",
              "IRT         500.0   98.036000   20.311470   42.00   83.000   97.000  111.000   \n",
              "MR          500.0    1.864000    0.700346    1.00    1.000    2.000    2.000   \n",
              "EA          500.0    1.106180    0.616587    0.00    0.780    0.940    1.210   \n",
              "DT          500.0  154.088000   42.800983   66.00  124.000  155.000  176.000   \n",
              "MPI         500.0    0.218860    0.175814    0.01    0.080    0.180    0.310   \n",
              "RR          500.0   20.482000    3.277065   11.00   18.000   20.000   22.000   \n",
              "TC          500.0  175.102000   46.698062   90.00  139.500  170.000  209.250   \n",
              "LDLc        500.0  113.420000   37.649310   35.00   87.000  106.000  140.000   \n",
              "HDLc        500.0   34.556000    6.143480   19.00   32.000   34.000   38.000   \n",
              "TG          500.0  170.766000  100.103430   45.00  105.000  140.000  210.000   \n",
              "BNP         500.0   86.518000  205.683215    5.00   13.000   20.000   25.000   \n",
              "\n",
              "                max  \n",
              "Age           95.00  \n",
              "BMI           48.89  \n",
              "HR           153.00  \n",
              "RBS           28.70  \n",
              "HbA1C         13.40  \n",
              "Creatinine    15.08  \n",
              "Na           149.00  \n",
              "K              6.00  \n",
              "Cl           110.00  \n",
              "Hb            16.70  \n",
              "TropI        126.00  \n",
              "LVIDd         78.00  \n",
              "FS            63.00  \n",
              "LVIDs         71.00  \n",
              "LVEF          75.00  \n",
              "LAV           57.00  \n",
              "ICT          148.00  \n",
              "IRT          185.00  \n",
              "MR             4.00  \n",
              "EA             5.30  \n",
              "DT           368.00  \n",
              "MPI            1.02  \n",
              "RR            42.00  \n",
              "TC           363.00  \n",
              "LDLc         260.00  \n",
              "HDLc          80.00  \n",
              "TG          1032.00  \n",
              "BNP         1184.00  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe(include=[np.number]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82df66cd-4724-42c8-b094-95ef4ec93ccf",
      "metadata": {
        "id": "82df66cd-4724-42c8-b094-95ef4ec93ccf"
      },
      "source": [
        "#### Summery of Statistical catagorical Colums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7hsrZ2GTtHus",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "7hsrZ2GTtHus",
        "outputId": "daa9610b-31fc-4afa-938d-627ad46a8be2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NYHA</th>\n",
              "      <td>500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HTN</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DM</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoker</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DL</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BA</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CXR</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECG</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RWMA</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MI</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACS</th>\n",
              "      <td>500</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wall</th>\n",
              "      <td>500</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thrombolysis</th>\n",
              "      <td>500</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chest_pain</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HF</th>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             count unique top freq\n",
              "Sex            500      2   1  358\n",
              "NYHA           500      4   2  182\n",
              "HTN            500      2   1  318\n",
              "DM             500      2   0  269\n",
              "Smoker         500      2   0  320\n",
              "DL             500      2   1  282\n",
              "BA             500      2   0  452\n",
              "CXR            500      2   0  392\n",
              "ECG            500      5   0  176\n",
              "RWMA           500      2   1  345\n",
              "MI             500      2   1  342\n",
              "ACS            500      3   2  196\n",
              "Wall           500      9   9  196\n",
              "Thrombolysis   500      4   0  345\n",
              "Chest_pain     500      2   1  339\n",
              "HF             500      2   1  274"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe(include=['object', 'category']).T  #No objects to concatenate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zZRe5h2mMmAQ",
      "metadata": {
        "id": "zZRe5h2mMmAQ"
      },
      "source": [
        "Plotting for categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0238345-eef5-45d4-ae1e-df1c4398f949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c0238345-eef5-45d4-ae1e-df1c4398f949",
        "outputId": "6633175d-cdc8-4313-93c6-f916e0a5c814",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Get the column names from the X_test DataFrame\n",
        "feature_names =data.columns.tolist()\n",
        "\n",
        "# Set up the plotting for categorical variables\n",
        "cat_cols = data.select_dtypes(include=[\"object\",'category']).columns\n",
        "\n",
        "# Loop through categorical columns and plot separate bar plots for each feature\n",
        "for col in cat_cols:\n",
        "    plt.figure(figsize=(10, 5))  # Create a new figure for each feature\n",
        "\n",
        "    # Countplot with multiple colors\n",
        "    sns.countplot(x=data[col], palette=['skyblue','lightcoral','red','olive'])  # You can change the palette to any you prefer\n",
        "\n",
        "    # Title for the plot\n",
        "    plt.title(f'Bar Plot of {col}')\n",
        "\n",
        "    # Calculate percentages\n",
        "    total = len(data[col])\n",
        "    ax = plt.gca()  # Get current axes\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        percentage = (height / total) * 100\n",
        "        ax.text(p.get_x() + p.get_width() / 2, height + 1, f'{percentage:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "    # Rotate x-axis labels to be vertical\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout for better spacing\n",
        "    plt.show()  # Show the plot for each feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a131986-183a-4c86-a5cf-15315a854a23",
      "metadata": {
        "id": "3a131986-183a-4c86-a5cf-15315a854a23"
      },
      "source": [
        "### Define the terget Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01de08aa-1395-4f19-9fad-75df0072f3fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01de08aa-1395-4f19-9fad-75df0072f3fc",
        "outputId": "e0e18448-52a8-4fa6-f8a5-4a6277cc734d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['0', '1'], dtype=object)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['HF'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3230be-b853-40f3-bef1-19c62b6722f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "fa3230be-b853-40f3-bef1-19c62b6722f7",
        "outputId": "aebb6784-8aee-4f0a-8a79-8345793fed6f"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "HF_counts = data['HF'].value_counts()\n",
        "HF_percentage = HF_counts / HF_counts.sum() * 100\n",
        "\n",
        "# Pie Chart with Shadows (Simulated 3D Effect)\n",
        "plt.figure(figsize=(6, 4))\n",
        "colors = ['skyblue','lightcoral','red','olive'][:len(HF_counts)]\n",
        "\n",
        "plt.pie(\n",
        "    HF_counts,\n",
        "    labels=HF_counts.index,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colors,\n",
        "    explode=[0.1] * len(HF_counts),  # Slightly separate each slice\n",
        "    shadow=True  # Add shadow for depth\n",
        ")\n",
        "plt.title('Heart Failure (HF) Status')\n",
        "plt.axis('equal')  # Ensures the pie chart is circular\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b0dee6-96a2-4c8e-90fa-6604cd2bcf1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "a8b0dee6-96a2-4c8e-90fa-6604cd2bcf1f",
        "outputId": "fc59e9c7-e43c-4fd6-e12e-dfcacb537fe6"
      },
      "outputs": [],
      "source": [
        "# Bar Chart with Enhancements\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "colors = sns.color_palette(\"cool\", len(HF_counts))  # Gradient color palette\n",
        "\n",
        "bars = ax.bar(HF_counts.index, HF_counts.values, color=['deepskyblue','lightcoral','red','olive'], edgecolor='white', linewidth=1.2)\n",
        "\n",
        "# Annotate bars\n",
        "for bar, percentage in zip(bars, HF_percentage):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height() + 0.5,\n",
        "        f'{int(bar.get_height())} ({percentage:.1f}%)',\n",
        "        ha='center',\n",
        "        va='bottom',\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "ax.set_title('Heart Failure (HF)', fontsize=14, weight='bold')\n",
        "ax.set_ylabel('Count', fontsize=12)\n",
        "ax.set_xlabel('Heart Failure (HF)', fontsize=12)\n",
        "plt.xticks(rotation=0, fontsize=10)\n",
        "sns.despine()  # Remove top and right spines for a cleaner look\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hd4nzPn7Mx2A",
      "metadata": {
        "id": "Hd4nzPn7Mx2A"
      },
      "source": [
        "Basic Statistics Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edNwEQhdRzmN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edNwEQhdRzmN",
        "outputId": "45c37cf5-1b54-448e-85d2-bb05b4579fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Statistics of the Dataset:\n",
            "               Age  Sex         BMI NYHA          HR  HTN   DM Smoker   DL  \\\n",
            "count   500.000000  500  500.000000  500  500.000000  500  500    500  500   \n",
            "unique         NaN    2         NaN    4         NaN    2    2      2    2   \n",
            "top            NaN    1         NaN    2         NaN    1    0      0    1   \n",
            "freq           NaN  358         NaN  182         NaN  318  269    320  282   \n",
            "mean     55.530000  NaN   25.378720  NaN   80.706000  NaN  NaN    NaN  NaN   \n",
            "std      12.696121  NaN    4.048717  NaN   14.923706  NaN  NaN    NaN  NaN   \n",
            "min      18.000000  NaN   12.260000  NaN   30.000000  NaN  NaN    NaN  NaN   \n",
            "25%      47.000000  NaN   22.815000  NaN   72.000000  NaN  NaN    NaN  NaN   \n",
            "50%      56.000000  NaN   24.800000  NaN   78.000000  NaN  NaN    NaN  NaN   \n",
            "75%      65.000000  NaN   27.550000  NaN   88.000000  NaN  NaN    NaN  NaN   \n",
            "max      95.000000  NaN   48.890000  NaN  153.000000  NaN  NaN    NaN  NaN   \n",
            "\n",
            "         BA  ...          DT         MPI          RR  Chest_pain          TC  \\\n",
            "count   500  ...  500.000000  500.000000  500.000000         500  500.000000   \n",
            "unique    2  ...         NaN         NaN         NaN           2         NaN   \n",
            "top       0  ...         NaN         NaN         NaN           1         NaN   \n",
            "freq    452  ...         NaN         NaN         NaN         339         NaN   \n",
            "mean    NaN  ...  154.088000    0.218860   20.482000         NaN  175.102000   \n",
            "std     NaN  ...   42.800983    0.175814    3.277065         NaN   46.698062   \n",
            "min     NaN  ...   66.000000    0.010000   11.000000         NaN   90.000000   \n",
            "25%     NaN  ...  124.000000    0.080000   18.000000         NaN  139.500000   \n",
            "50%     NaN  ...  155.000000    0.180000   20.000000         NaN  170.000000   \n",
            "75%     NaN  ...  176.000000    0.310000   22.000000         NaN  209.250000   \n",
            "max     NaN  ...  368.000000    1.020000   42.000000         NaN  363.000000   \n",
            "\n",
            "             LDLc       HDLc          TG          BNP   HF  \n",
            "count   500.00000  500.00000   500.00000   500.000000  500  \n",
            "unique        NaN        NaN         NaN          NaN    2  \n",
            "top           NaN        NaN         NaN          NaN    1  \n",
            "freq          NaN        NaN         NaN          NaN  274  \n",
            "mean    113.42000   34.55600   170.76600    86.518000  NaN  \n",
            "std      37.64931    6.14348   100.10343   205.683215  NaN  \n",
            "min      35.00000   19.00000    45.00000     5.000000  NaN  \n",
            "25%      87.00000   32.00000   105.00000    13.000000  NaN  \n",
            "50%     106.00000   34.00000   140.00000    20.000000  NaN  \n",
            "75%     140.00000   38.00000   210.00000    25.000000  NaN  \n",
            "max     260.00000   80.00000  1032.00000  1184.000000  NaN  \n",
            "\n",
            "[11 rows x 44 columns]\n",
            "\n",
            "Missing Values in the Dataset:\n",
            "Age             0\n",
            "Sex             0\n",
            "BMI             0\n",
            "NYHA            0\n",
            "HR              0\n",
            "HTN             0\n",
            "DM              0\n",
            "Smoker          0\n",
            "DL              0\n",
            "BA              0\n",
            "RBS             0\n",
            "HbA1C           0\n",
            "Creatinine      0\n",
            "Na              0\n",
            "K               0\n",
            "Cl              0\n",
            "Hb              0\n",
            "TropI           0\n",
            "CXR             0\n",
            "ECG             0\n",
            "LVIDd           0\n",
            "FS              0\n",
            "LVIDs           0\n",
            "LVEF            0\n",
            "RWMA            0\n",
            "LAV             0\n",
            "MI              0\n",
            "ACS             0\n",
            "Wall            0\n",
            "Thrombolysis    0\n",
            "ICT             0\n",
            "IRT             0\n",
            "MR              0\n",
            "EA              0\n",
            "DT              0\n",
            "MPI             0\n",
            "RR              0\n",
            "Chest_pain      0\n",
            "TC              0\n",
            "LDLc            0\n",
            "HDLc            0\n",
            "TG              0\n",
            "BNP             0\n",
            "HF              0\n",
            "dtype: int64\n",
            "\n",
            "Data Types of the Columns:\n",
            "Age             float64\n",
            "Sex              object\n",
            "BMI             float64\n",
            "NYHA             object\n",
            "HR              float64\n",
            "HTN              object\n",
            "DM               object\n",
            "Smoker           object\n",
            "DL               object\n",
            "BA               object\n",
            "RBS             float64\n",
            "HbA1C           float64\n",
            "Creatinine      float64\n",
            "Na              float64\n",
            "K               float64\n",
            "Cl              float64\n",
            "Hb              float64\n",
            "TropI           float64\n",
            "CXR              object\n",
            "ECG              object\n",
            "LVIDd           float64\n",
            "FS              float64\n",
            "LVIDs           float64\n",
            "LVEF            float64\n",
            "RWMA             object\n",
            "LAV             float64\n",
            "MI               object\n",
            "ACS              object\n",
            "Wall             object\n",
            "Thrombolysis     object\n",
            "ICT             float64\n",
            "IRT             float64\n",
            "MR                int64\n",
            "EA              float64\n",
            "DT              float64\n",
            "MPI             float64\n",
            "RR              float64\n",
            "Chest_pain       object\n",
            "TC              float64\n",
            "LDLc            float64\n",
            "HDLc            float64\n",
            "TG              float64\n",
            "BNP             float64\n",
            "HF               object\n",
            "dtype: object\n",
            "\n",
            "Unique Values per Column:\n",
            "Age              63\n",
            "Sex               2\n",
            "BMI             292\n",
            "NYHA              4\n",
            "HR               70\n",
            "HTN               2\n",
            "DM                2\n",
            "Smoker            2\n",
            "DL                2\n",
            "BA                2\n",
            "RBS             109\n",
            "HbA1C            70\n",
            "Creatinine      115\n",
            "Na               24\n",
            "K                30\n",
            "Cl               18\n",
            "Hb               61\n",
            "TropI           221\n",
            "CXR               2\n",
            "ECG               5\n",
            "LVIDd            44\n",
            "FS               37\n",
            "LVIDs            45\n",
            "LVEF             41\n",
            "RWMA              2\n",
            "LAV              45\n",
            "MI                2\n",
            "ACS               3\n",
            "Wall              9\n",
            "Thrombolysis      4\n",
            "ICT              75\n",
            "IRT              84\n",
            "MR                4\n",
            "EA              158\n",
            "DT              150\n",
            "MPI              71\n",
            "RR               23\n",
            "Chest_pain        2\n",
            "TC              144\n",
            "LDLc            134\n",
            "HDLc             38\n",
            "TG              179\n",
            "BNP              88\n",
            "HF                2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame called `df`\n",
        "\n",
        "# 1. Basic Statistics Summary using describe()\n",
        "print(\"Basic Statistics of the Dataset:\")\n",
        "print(data.describe(include='all'))  # Describe all columns, including categorical features\n",
        "\n",
        "# 2. Check for missing values in each column\n",
        "print(\"\\nMissing Values in the Dataset:\")\n",
        "print(data.isnull().sum())  # Sum of missing values per column\n",
        "\n",
        "# 3. Data Types of the Columns\n",
        "print(\"\\nData Types of the Columns:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "\n",
        "# 5. Check for unique values in each column\n",
        "print(\"\\nUnique Values per Column:\")\n",
        "print(data.nunique())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gCFFawQgpsPI",
      "metadata": {
        "id": "gCFFawQgpsPI"
      },
      "outputs": [],
      "source": [
        "dataf=data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t94XkvoTtes5",
      "metadata": {
        "id": "t94XkvoTtes5"
      },
      "source": [
        "### Apply Model Without Fearures selections(or With 47 Columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ybxA0fIDwVV_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybxA0fIDwVV_",
        "outputId": "7d603048-e35c-48bd-c046-8b19682cd342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Age  Sex    BMI  NYHA    HR  HTN  DM  Smoker  DL  BA  ...  Wall_9  \\\n",
            "0    50.0    0  28.72     0  74.0    1   1       1   1   0  ...    True   \n",
            "1    74.0    1  23.88     0  84.0    0   1       0   1   0  ...    True   \n",
            "2    51.0    1  25.24     0  78.0    0   1       0   1   0  ...   False   \n",
            "3    68.0    1  27.85     0  72.0    1   1       0   0   0  ...   False   \n",
            "4    34.0    1  21.61     0  72.0    0   0       1   0   0  ...   False   \n",
            "..    ...  ...    ...   ...   ...  ...  ..     ...  ..  ..  ...     ...   \n",
            "495  73.0    0  40.06     2  69.0    1   1       0   1   0  ...   False   \n",
            "496  35.0    0  36.95     3  78.0    1   0       0   1   0  ...   False   \n",
            "497  62.0    1  21.22     0  75.0    1   0       1   0   0  ...    True   \n",
            "498  61.0    1  22.95     1  80.0    1   1       0   1   0  ...    True   \n",
            "499  65.0    1  28.04     2  53.0    1   1       1   1   0  ...   False   \n",
            "\n",
            "      MR_2   MR_3   MR_4  Thrombolysis_1  Thrombolysis_2  Thrombolysis_3  \\\n",
            "0    False  False  False           False           False           False   \n",
            "1    False  False  False           False           False           False   \n",
            "2    False  False  False           False           False           False   \n",
            "3    False  False  False           False           False           False   \n",
            "4    False  False  False           False           False           False   \n",
            "..     ...    ...    ...             ...             ...             ...   \n",
            "495  False   True  False           False           False            True   \n",
            "496  False   True  False           False            True           False   \n",
            "497  False   True  False           False           False           False   \n",
            "498  False   True  False           False           False           False   \n",
            "499  False  False   True           False           False            True   \n",
            "\n",
            "      MR_2   MR_3   MR_4  \n",
            "0    False  False  False  \n",
            "1    False  False  False  \n",
            "2    False  False  False  \n",
            "3    False  False  False  \n",
            "4    False  False  False  \n",
            "..     ...    ...    ...  \n",
            "495  False   True  False  \n",
            "496  False   True  False  \n",
            "497  False   True  False  \n",
            "498  False   True  False  \n",
            "499  False  False   True  \n",
            "\n",
            "[500 rows x 62 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Function to perform encoding based on the recommended encoding method\n",
        "def encode_columns(data):\n",
        "    # Label Encoder initialization\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Define the columns and their respective encoding methods\n",
        "    label_encoding_columns = [\n",
        "        'Sex', 'NYHA','HTN','DM', 'Smoker', 'DL', 'BA','CXR','RWMA', 'MI',\n",
        "        'Chest_pain', 'HF'\n",
        "    ]\n",
        "\n",
        "    one_hot_encoding_columns = [\n",
        "        'ECG', 'ACS', 'Wall','MR','Thrombolysis','MR'\n",
        "    ]\n",
        "\n",
        "    # Apply Label Encoding to binary categorical variables\n",
        "    for col in label_encoding_columns:\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "\n",
        "    # Apply One-Hot Encoding to nominal categorical variables\n",
        "    data = pd.get_dummies(data, columns=one_hot_encoding_columns, drop_first=True)\n",
        "\n",
        "    return data # Changed 'df' to 'data' to return the modified DataFrame\n",
        "\n",
        "# Encode the dataset\n",
        "encoded_data = encode_columns(data)\n",
        "\n",
        "# Display the encoded dataset\n",
        "print(encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rr-Y2UtQtV3u",
      "metadata": {
        "id": "Rr-Y2UtQtV3u"
      },
      "outputs": [],
      "source": [
        "# Splitting data into train and test sets\n",
        "X = data.drop(columns=['HF'])  # Target variable\n",
        "y = data['HF']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3lFN61tdM-n5",
      "metadata": {
        "id": "3lFN61tdM-n5"
      },
      "source": [
        "Use Robust Scaling: Instead of standard scaling, use sklearn.preprocessing.RobustScaler() to reduce the effect of outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wvBfy2JW62d_",
      "metadata": {
        "id": "wvBfy2JW62d_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Initialize RobustScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit and transform training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform test data (avoid data leakage by not fitting on test data)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OlX_ZZuu__yF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OlX_ZZuu__yF",
        "outputId": "be62e12e-c75c-4fd3-be9e-7db7a7c9a2fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.020882</td>\n",
              "      <td>0.712556</td>\n",
              "      <td>-1.882353</td>\n",
              "      <td>-0.470588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>1.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.287500</td>\n",
              "      <td>0.453163</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.118801</td>\n",
              "      <td>0.852797</td>\n",
              "      <td>-2.065910</td>\n",
              "      <td>-0.420854</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.579146</td>\n",
              "      <td>5.205835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NYHA</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.001250</td>\n",
              "      <td>0.449866</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HR</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.153281</td>\n",
              "      <td>0.940222</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>4.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HTN</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.355000</td>\n",
              "      <td>0.479113</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DM</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.499724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoker</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.478347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DL</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.427500</td>\n",
              "      <td>0.495335</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BA</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.275470</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBS</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.323743</td>\n",
              "      <td>0.928480</td>\n",
              "      <td>-0.776316</td>\n",
              "      <td>-0.302632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.697368</td>\n",
              "      <td>5.723684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HbA1C</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.355658</td>\n",
              "      <td>0.923942</td>\n",
              "      <td>-1.315789</td>\n",
              "      <td>-0.210526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>4.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Creatinine</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>4.076873</td>\n",
              "      <td>-1.619048</td>\n",
              "      <td>-0.420635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.579365</td>\n",
              "      <td>44.317460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.792697</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.916518</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cl</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.205000</td>\n",
              "      <td>0.852243</td>\n",
              "      <td>-2.166667</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hb</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.079773</td>\n",
              "      <td>0.685042</td>\n",
              "      <td>-2.045455</td>\n",
              "      <td>-0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TropI</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.381130</td>\n",
              "      <td>1.179333</td>\n",
              "      <td>-0.432756</td>\n",
              "      <td>-0.432423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.567577</td>\n",
              "      <td>7.956059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CXR</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>0.406024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECG</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.076667</td>\n",
              "      <td>0.521560</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDd</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.824187</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>2.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FS</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.044167</td>\n",
              "      <td>0.609061</td>\n",
              "      <td>-1.375000</td>\n",
              "      <td>-0.458333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>1.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVIDs</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.150455</td>\n",
              "      <td>0.766492</td>\n",
              "      <td>-1.636364</td>\n",
              "      <td>-0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>2.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVEF</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.056625</td>\n",
              "      <td>0.584748</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RWMA</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.305000</td>\n",
              "      <td>0.460984</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAV</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.003214</td>\n",
              "      <td>0.659588</td>\n",
              "      <td>-1.642857</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MI</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.310000</td>\n",
              "      <td>0.463072</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACS</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.003750</td>\n",
              "      <td>0.388572</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wall</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.004063</td>\n",
              "      <td>0.450936</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thrombolysis</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.622500</td>\n",
              "      <td>0.998743</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICT</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.008764</td>\n",
              "      <td>0.768122</td>\n",
              "      <td>-2.067416</td>\n",
              "      <td>-0.449438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>2.696629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IRT</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.730495</td>\n",
              "      <td>-1.857143</td>\n",
              "      <td>-0.464286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>3.178571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MR</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.155000</td>\n",
              "      <td>0.715720</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EA</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.343011</td>\n",
              "      <td>1.414861</td>\n",
              "      <td>-2.159091</td>\n",
              "      <td>-0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>9.886364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.003483</td>\n",
              "      <td>0.872246</td>\n",
              "      <td>-1.592040</td>\n",
              "      <td>-0.597015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402985</td>\n",
              "      <td>4.238806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MPI</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.181087</td>\n",
              "      <td>0.782406</td>\n",
              "      <td>-0.739130</td>\n",
              "      <td>-0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>3.652174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RR</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.123125</td>\n",
              "      <td>0.821277</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chest_pain</th>\n",
              "      <td>400.0</td>\n",
              "      <td>-0.345000</td>\n",
              "      <td>0.475964</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TC</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.070423</td>\n",
              "      <td>0.706498</td>\n",
              "      <td>-1.230769</td>\n",
              "      <td>-0.461538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>2.415385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDLc</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.122356</td>\n",
              "      <td>0.720754</td>\n",
              "      <td>-1.384615</td>\n",
              "      <td>-0.384615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>2.942308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDLc</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.074643</td>\n",
              "      <td>0.921051</td>\n",
              "      <td>-2.142857</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TG</th>\n",
              "      <td>400.0</td>\n",
              "      <td>0.310238</td>\n",
              "      <td>1.003656</td>\n",
              "      <td>-0.902613</td>\n",
              "      <td>-0.334917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.665083</td>\n",
              "      <td>8.475059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BNP</th>\n",
              "      <td>400.0</td>\n",
              "      <td>5.781600</td>\n",
              "      <td>17.173486</td>\n",
              "      <td>-1.200000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>93.120000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              count      mean        std       min       25%  50%       75%  \\\n",
              "Age           400.0  0.020882   0.712556 -1.882353 -0.470588  0.0  0.529412   \n",
              "Sex           400.0 -0.287500   0.453163 -1.000000 -1.000000  0.0  0.000000   \n",
              "BMI           400.0  0.118801   0.852797 -2.065910 -0.420854  0.0  0.579146   \n",
              "NYHA          400.0  0.001250   0.449866 -0.500000 -0.500000  0.0  0.500000   \n",
              "HR            400.0  0.153281   0.940222 -3.000000 -0.375000  0.0  0.625000   \n",
              "HTN           400.0 -0.355000   0.479113 -1.000000 -1.000000  0.0  0.000000   \n",
              "DM            400.0  0.470000   0.499724  0.000000  0.000000  0.0  1.000000   \n",
              "Smoker        400.0  0.352500   0.478347  0.000000  0.000000  0.0  1.000000   \n",
              "DL            400.0 -0.427500   0.495335 -1.000000 -1.000000  0.0  0.000000   \n",
              "BA            400.0  0.082500   0.275470  0.000000  0.000000  0.0  0.000000   \n",
              "RBS           400.0  0.323743   0.928480 -0.776316 -0.302632  0.0  0.697368   \n",
              "HbA1C         400.0  0.355658   0.923942 -1.315789 -0.210526  0.0  0.789474   \n",
              "Creatinine    400.0  0.735000   4.076873 -1.619048 -0.420635  0.0  0.579365   \n",
              "Na            400.0  0.101500   0.792697 -3.000000 -0.400000  0.0  0.600000   \n",
              "K             400.0  0.048000   0.916518 -2.250000 -0.500000  0.0  0.500000   \n",
              "Cl            400.0 -0.205000   0.852243 -2.166667 -0.666667  0.0  0.333333   \n",
              "Hb            400.0  0.079773   0.685042 -2.045455 -0.454545  0.0  0.545455   \n",
              "TropI         400.0  0.381130   1.179333 -0.432756 -0.432423  0.0  0.567577   \n",
              "CXR           400.0  0.207500   0.406024  0.000000  0.000000  0.0  0.000000   \n",
              "ECG           400.0 -0.076667   0.521560 -0.666667 -0.666667  0.0  0.333333   \n",
              "LVIDd         400.0  0.066944   0.824187 -3.000000 -0.444444  0.0  0.555556   \n",
              "FS            400.0  0.044167   0.609061 -1.375000 -0.458333  0.0  0.541667   \n",
              "LVIDs         400.0  0.150455   0.766492 -1.636364 -0.454545  0.0  0.545455   \n",
              "LVEF          400.0 -0.056625   0.584748 -1.500000 -0.500000  0.0  0.500000   \n",
              "RWMA          400.0 -0.305000   0.460984 -1.000000 -1.000000  0.0  0.000000   \n",
              "LAV           400.0  0.003214   0.659588 -1.642857 -0.500000  0.0  0.500000   \n",
              "MI            400.0 -0.310000   0.463072 -1.000000 -1.000000  0.0  0.000000   \n",
              "ACS           400.0 -0.003750   0.388572 -0.500000 -0.500000  0.0  0.500000   \n",
              "Wall          400.0  0.004063   0.450936 -0.500000 -0.500000  0.0  0.500000   \n",
              "Thrombolysis  400.0  0.622500   0.998743  0.000000  0.000000  0.0  1.000000   \n",
              "ICT           400.0  0.008764   0.768122 -2.067416 -0.449438  0.0  0.550562   \n",
              "IRT           400.0  0.075000   0.730495 -1.857143 -0.464286  0.0  0.535714   \n",
              "MR            400.0 -0.155000   0.715720 -1.000000 -1.000000  0.0  0.000000   \n",
              "EA            400.0  0.343011   1.414861 -2.159091 -0.409091  0.0  0.590909   \n",
              "DT            400.0 -0.003483   0.872246 -1.592040 -0.597015  0.0  0.402985   \n",
              "MPI           400.0  0.181087   0.782406 -0.739130 -0.434783  0.0  0.565217   \n",
              "RR            400.0  0.123125   0.821277 -2.250000 -0.500000  0.0  0.500000   \n",
              "Chest_pain    400.0 -0.345000   0.475964 -1.000000 -1.000000  0.0  0.000000   \n",
              "TC            400.0  0.070423   0.706498 -1.230769 -0.461538  0.0  0.538462   \n",
              "LDLc          400.0  0.122356   0.720754 -1.384615 -0.384615  0.0  0.615385   \n",
              "HDLc          400.0  0.074643   0.921051 -2.142857 -0.428571  0.0  0.571429   \n",
              "TG            400.0  0.310238   1.003656 -0.902613 -0.334917  0.0  0.665083   \n",
              "BNP           400.0  5.781600  17.173486 -1.200000 -0.500000  0.0  0.500000   \n",
              "\n",
              "                    max  \n",
              "Age            1.823529  \n",
              "Sex            0.000000  \n",
              "BMI            5.205835  \n",
              "NYHA           1.000000  \n",
              "HR             4.687500  \n",
              "HTN            0.000000  \n",
              "DM             1.000000  \n",
              "Smoker         1.000000  \n",
              "DL             0.000000  \n",
              "BA             1.000000  \n",
              "RBS            5.723684  \n",
              "HbA1C          4.105263  \n",
              "Creatinine    44.317460  \n",
              "Na             2.200000  \n",
              "K              5.250000  \n",
              "Cl             1.166667  \n",
              "Hb             2.000000  \n",
              "TropI          7.956059  \n",
              "CXR            1.000000  \n",
              "ECG            0.666667  \n",
              "LVIDd          2.555556  \n",
              "FS             1.875000  \n",
              "LVIDs          2.727273  \n",
              "LVEF           1.100000  \n",
              "RWMA           0.000000  \n",
              "LAV            1.571429  \n",
              "MI             0.000000  \n",
              "ACS            0.500000  \n",
              "Wall           0.500000  \n",
              "Thrombolysis   3.000000  \n",
              "ICT            2.696629  \n",
              "IRT            3.178571  \n",
              "MR             2.000000  \n",
              "EA             9.886364  \n",
              "DT             4.238806  \n",
              "MPI            3.652174  \n",
              "RR             5.500000  \n",
              "Chest_pain     0.000000  \n",
              "TC             2.415385  \n",
              "LDLc           2.942308  \n",
              "HDLc           6.571429  \n",
              "TG             8.475059  \n",
              "BNP           93.120000  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the NumPy array back to a pandas DataFrame\n",
        "X_train = pd.DataFrame(X_train, columns=X.columns) # Assuming X was your original DataFrame\n",
        "\n",
        "# Now you can use the head() method\n",
        "X_train.describe(include=[np.number]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ed1X7CRvNNyx",
      "metadata": {
        "id": "Ed1X7CRvNNyx"
      },
      "source": [
        "Evaluate models and store results in a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c44cce8-95ab-45f9-967f-d7d07a9ceca4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c44cce8-95ab-45f9-967f-d7d07a9ceca4",
        "outputId": "e654fae2-1b60-4e21-feea-bbadfa734318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sorted Results by Accuracy:\n",
            "                           Model  Accuracy  Precision (Class 0)  \\\n",
            "11                      LightGBM      0.84             0.853659   \n",
            "4                  Random Forest      0.82             0.846154   \n",
            "6               Ridge Classifier      0.82             0.829268   \n",
            "9              Gradient Boosting      0.82             0.846154   \n",
            "10        Extra Trees Classifier      0.82             0.829268   \n",
            "14                      CatBoost      0.82             0.935484   \n",
            "13                       XGBoost      0.81             0.795455   \n",
            "0            Logistic Regression      0.80             0.804878   \n",
            "12  Multi-Layer Perceptron (MLP)      0.80             0.804878   \n",
            "7   Linear Discriminant Analysis      0.79             0.815789   \n",
            "3                  Decision Tree      0.77             0.750000   \n",
            "5         Support Vector Machine      0.77             0.761905   \n",
            "2                    Naive Bayes      0.76             0.783784   \n",
            "8                       AdaBoost      0.76             0.744186   \n",
            "1            K-Nearest Neighbors      0.72             0.680851   \n",
            "\n",
            "    Recall (Class 0)  F1 Score (Class 0)  Precision (Class 1)  \\\n",
            "11          0.777778            0.813953             0.830508   \n",
            "4           0.733333            0.785714             0.803279   \n",
            "6           0.755556            0.790698             0.813559   \n",
            "9           0.733333            0.785714             0.803279   \n",
            "10          0.755556            0.790698             0.813559   \n",
            "14          0.644444            0.763158             0.768116   \n",
            "13          0.777778            0.786517             0.821429   \n",
            "0           0.733333            0.767442             0.796610   \n",
            "12          0.733333            0.767442             0.796610   \n",
            "7           0.688889            0.746988             0.774194   \n",
            "3           0.733333            0.741573             0.785714   \n",
            "5           0.711111            0.735632             0.775862   \n",
            "2           0.644444            0.707317             0.746032   \n",
            "8           0.711111            0.727273             0.771930   \n",
            "1           0.711111            0.695652             0.754717   \n",
            "\n",
            "    Recall (Class 1)  F1 Score (Class 1)  Precision (Class macro avg)  \\\n",
            "11          0.890909            0.859649                     0.842084   \n",
            "4           0.890909            0.844828                     0.824716   \n",
            "6           0.872727            0.842105                     0.821414   \n",
            "9           0.890909            0.844828                     0.824716   \n",
            "10          0.872727            0.842105                     0.821414   \n",
            "14          0.963636            0.854839                     0.851800   \n",
            "13          0.836364            0.828829                     0.808442   \n",
            "0           0.854545            0.824561                     0.800744   \n",
            "12          0.854545            0.824561                     0.800744   \n",
            "7           0.872727            0.820513                     0.794992   \n",
            "3           0.800000            0.792793                     0.767857   \n",
            "5           0.818182            0.796460                     0.768883   \n",
            "2           0.854545            0.796610                     0.764908   \n",
            "8           0.800000            0.785714                     0.758058   \n",
            "1           0.727273            0.740741                     0.717784   \n",
            "\n",
            "    Recall (Class macro avg)  F1 Score (Class macro avg)  \\\n",
            "11                  0.834343                    0.836801   \n",
            "4                   0.812121                    0.815271   \n",
            "6                   0.814141                    0.816401   \n",
            "9                   0.812121                    0.815271   \n",
            "10                  0.814141                    0.816401   \n",
            "14                  0.804040                    0.808998   \n",
            "13                  0.807071                    0.807673   \n",
            "0                   0.793939                    0.796002   \n",
            "12                  0.793939                    0.796002   \n",
            "7                   0.780808                    0.783750   \n",
            "3                   0.766667                    0.767183   \n",
            "5                   0.764646                    0.766046   \n",
            "2                   0.749495                    0.751964   \n",
            "8                   0.755556                    0.756494   \n",
            "1                   0.719192                    0.718196   \n",
            "\n",
            "    Precision (Class weighted avg)  Recall (Class weighted avg)  \\\n",
            "11                        0.840926                         0.84   \n",
            "4                         0.822573                         0.82   \n",
            "6                         0.820628                         0.82   \n",
            "9                         0.822573                         0.82   \n",
            "10                        0.820628                         0.82   \n",
            "14                        0.843432                         0.82   \n",
            "13                        0.809740                         0.81   \n",
            "0                         0.800331                         0.80   \n",
            "12                        0.800331                         0.80   \n",
            "7                         0.792912                         0.79   \n",
            "3                         0.769643                         0.77   \n",
            "5                         0.769581                         0.77   \n",
            "2                         0.763020                         0.76   \n",
            "8                         0.759445                         0.76   \n",
            "1                         0.721477                         0.72   \n",
            "\n",
            "    F1 Score (Class weighted avg)  \n",
            "11                       0.839086  \n",
            "4                        0.818227  \n",
            "6                        0.818972  \n",
            "9                        0.818227  \n",
            "10                       0.818972  \n",
            "14                       0.813582  \n",
            "13                       0.809788  \n",
            "0                        0.798858  \n",
            "12                       0.798858  \n",
            "7                        0.787427  \n",
            "3                        0.769744  \n",
            "5                        0.769088  \n",
            "2                        0.756428  \n",
            "8                        0.759416  \n",
            "1                        0.720451  \n",
            "\n",
            "Top 3 Best Models Based on Overall Performance:\n",
            "\n",
            "               Model  Accuracy  Precision (Class 0)  Recall (Class 0)  \\\n",
            "11          LightGBM      0.84             0.853659          0.777778   \n",
            "4      Random Forest      0.82             0.846154          0.733333   \n",
            "6   Ridge Classifier      0.82             0.829268          0.755556   \n",
            "\n",
            "    F1 Score (Class 0)  Precision (Class 1)  Recall (Class 1)  \\\n",
            "11            0.813953             0.830508          0.890909   \n",
            "4             0.785714             0.803279          0.890909   \n",
            "6             0.790698             0.813559          0.872727   \n",
            "\n",
            "    F1 Score (Class 1)  Precision (Class macro avg)  Recall (Class macro avg)  \\\n",
            "11            0.859649                     0.842084                  0.834343   \n",
            "4             0.844828                     0.824716                  0.812121   \n",
            "6             0.842105                     0.821414                  0.814141   \n",
            "\n",
            "    F1 Score (Class macro avg)  Precision (Class weighted avg)  \\\n",
            "11                    0.836801                        0.840926   \n",
            "4                     0.815271                        0.822573   \n",
            "6                     0.816401                        0.820628   \n",
            "\n",
            "    Recall (Class weighted avg)  F1 Score (Class weighted avg)  \n",
            "11                         0.84                       0.839086  \n",
            "4                          0.82                       0.818227  \n",
            "6                          0.82                       0.818972  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Set global seed for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Define models with fixed random_state\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "models = {\n",
        "    # 🔹 Logistic Regression: Strong regularization for better generalization\n",
        "    'Logistic Regression': LogisticRegression(\n",
        "        C=0.3, solver='liblinear', penalty='l1', class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 K-Nearest Neighbors: Reducing overfitting with distance-based weighting\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(\n",
        "        n_neighbors=5, weights='distance', algorithm='ball_tree', leaf_size=20, p=2\n",
        "    ),\n",
        "\n",
        "    # 🔹 Naive Bayes: Adjusted for better probability estimation\n",
        "    'Naive Bayes': GaussianNB(var_smoothing=1e-8),\n",
        "\n",
        "    # 🔹 Decision Tree: More depth and splitting to capture complex patterns\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        criterion='entropy', max_depth=20, min_samples_split=3, min_samples_leaf=2, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Random Forest: More trees & depth for higher accuracy\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=300, max_depth=15, min_samples_split=3, min_samples_leaf=1,\n",
        "        class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Support Vector Machine: Higher C, balanced class weights\n",
        "    'Support Vector Machine': SVC(\n",
        "        C=5.0, kernel='rbf', gamma='scale', probability=True, class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Ridge Classifier: Optimized regularization for stability\n",
        "    'Ridge Classifier': RidgeClassifier(alpha=0.3, class_weight='balanced'),\n",
        "\n",
        "    # 🔹 Quadratic Discriminant Analysis: Optimized for stability\n",
        "     #'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(reg_param=0.03),\n",
        "\n",
        "    # 🔹 Linear Discriminant Analysis: Optimized shrinkage\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'),\n",
        "\n",
        "    # 🔹 AdaBoost: More estimators & lower learning rate\n",
        "    'AdaBoost': AdaBoostClassifier(\n",
        "        n_estimators=200, learning_rate=0.05, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Gradient Boosting: Lower learning rate, more estimators\n",
        "    'Gradient Boosting': GradientBoostingClassifier(\n",
        "        learning_rate=0.03, n_estimators=250, max_depth=10, min_samples_split=3,\n",
        "        min_samples_leaf=2, subsample=0.85, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Extra Trees Classifier: Higher estimators for robustness\n",
        "    'Extra Trees Classifier': ExtraTreesClassifier(\n",
        "        n_estimators=300, max_depth=12, min_samples_split=4, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 LightGBM: Optimized for best recall & precision\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        colsample_bytree=0.9, learning_rate=0.03, max_depth=20, min_child_samples=5,\n",
        "        n_estimators=250, num_leaves=90, subsample=0.85, class_weight='balanced',verbose=-1,random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Multi-Layer Perceptron (MLP): More layers & epochs for better feature learning\n",
        "    'Multi-Layer Perceptron (MLP)': MLPClassifier(\n",
        "        hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', alpha=0.0001,\n",
        "        batch_size=16, learning_rate='adaptive', max_iter=500, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 XGBoost: Tuned for high performance\n",
        "    'XGBoost': XGBClassifier(\n",
        "        colsample_bytree=0.8, learning_rate=0.03, max_depth=12, min_child_weight=4,\n",
        "        n_estimators=250, subsample=0.85, gamma=0.1, reg_alpha=0.1, reg_lambda=0.1,\n",
        "        scale_pos_weight=1, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 CatBoost: Tuned for medical applications\n",
        "    'CatBoost': CatBoostClassifier(\n",
        "        iterations=250, learning_rate=0.03, depth=14, min_data_in_leaf=5,\n",
        "        subsample=0.85, l2_leaf_reg=3, class_weights=[1, 4], random_state=SEED, verbose=0\n",
        "    )\n",
        "}\n",
        "\n",
        "# Evaluate models and store results in a DataFrame\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Convert y_test and y_pred to integers before calculating accuracy\n",
        "        accuracy = accuracy_score(y_test.astype(int), y_pred.astype(int))\n",
        "\n",
        "        # Get classification report for multi-class classification\n",
        "        report = classification_report(y_test.astype(int), y_pred.astype(int), output_dict=True)\n",
        "\n",
        "        # Collect results dynamically for each class\n",
        "        model_result = {\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "        }\n",
        "\n",
        "        # Add Precision, Recall, F1 score for each class dynamically\n",
        "        for label in report.keys():\n",
        "            if label != 'accuracy':  # Exclude the accuracy key\n",
        "                model_result[f'Precision (Class {label})'] = report[label]['precision']\n",
        "                model_result[f'Recall (Class {label})'] = report[label]['recall']\n",
        "                model_result[f'F1 Score (Class {label})'] = report[label]['f1-score']\n",
        "\n",
        "        results.append(model_result)\n",
        "\n",
        "    # Create a DataFrame from results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "# Run evaluation with models\n",
        "# Convert target variable to integers\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "# Run evaluation with models\n",
        "results_df = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Sort results by accuracy\n",
        "sorted_results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "# Display the sorted results\n",
        "print(\"\\nSorted Results by Accuracy:\")\n",
        "print(sorted_results_df)\n",
        "\n",
        "# Print the best three models\n",
        "print(\"\\nTop 3 Best Models Based on Overall Performance:\\n\")\n",
        "print(sorted_results_df.head(3))\n",
        "\n",
        "# Store best models\n",
        "best_models = sorted_results_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "slxXkj9dqLcC",
      "metadata": {
        "id": "slxXkj9dqLcC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "TyKPom4FNUMD",
      "metadata": {
        "id": "TyKPom4FNUMD"
      },
      "source": [
        "Function to create a comparison plot with line graphs for all metrics in one plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ufQ1COZMwwnt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "ufQ1COZMwwnt",
        "outputId": "26b20a3b-91fc-4128-96b3-5e3b727dfd9d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to create a comparison plot with line graphs for all metrics in one plot\n",
        "def plot_model_comparison_all_metrics(sorted_results_df):\n",
        "    # Set the plot style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Prepare the data for plotting\n",
        "    metrics = [\n",
        "        'Accuracy',\n",
        "        'Precision (Class macro avg)',\n",
        "        'Recall (Class macro avg)',\n",
        "        'F1 Score (Class macro avg)',\n",
        "        'Precision (Class weighted avg)',\n",
        "        'Recall (Class weighted avg)',\n",
        "        'F1 Score (Class weighted avg)'\n",
        "    ]\n",
        "\n",
        "    # Create the figure and axis for plotting\n",
        "    plt.figure(figsize=(14, 8))  # Adjusted plot size\n",
        "\n",
        "    # Define a color palette for distinct line colors\n",
        "    color_palette = sns.color_palette(\"Set2\", len(metrics))  # Choose a different color for each metric\n",
        "\n",
        "    # Iterate through each metric and plot its value\n",
        "    for i, metric in enumerate(metrics):\n",
        "        sns.lineplot(x='Model', y=metric, data=sorted_results_df, label=metric,\n",
        "                     marker='o', linewidth=2, color=color_palette[i])\n",
        "\n",
        "    # Set the title and labels with larger fonts\n",
        "    plt.title('Comparison of Metrics for Each Model (Before Cross-Validation and Without Feature Selection)', fontsize=18)\n",
        "    plt.xlabel('Model', fontsize=16)\n",
        "    plt.ylabel('Score', fontsize=16)\n",
        "    plt.xticks(rotation=90, fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend(title='Metrics', fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_model_comparison_all_metrics(sorted_results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jm6FmuQD8Hqy",
      "metadata": {
        "id": "jm6FmuQD8Hqy"
      },
      "source": [
        "## Features Selections part\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OwIFp2L-Nuni",
      "metadata": {
        "id": "OwIFp2L-Nuni"
      },
      "source": [
        "### Selected Important Features Based on Variance Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UMJ2L0X6e_Hs",
      "metadata": {
        "id": "UMJ2L0X6e_Hs"
      },
      "source": [
        "Recall data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H7p3rYon8NNI",
      "metadata": {
        "id": "H7p3rYon8NNI"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "#dataf =dataf.drop(columns=['StudyID'])\n",
        "# Splitting data into train and test sets\n",
        "X = dataf.drop(columns=['HF'])  # Target variable\n",
        "y = dataf['HF']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uvj3Dinb8NJk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvj3Dinb8NJk",
        "outputId": "f6f013e8-3cae-431b-e530-3545571e8c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Age', 'Sex', 'BMI', 'NYHA', 'HR', 'HTN', 'DM', 'Smoker', 'DL', 'BA',\n",
            "       'RBS', 'HbA1C', 'Creatinine', 'Na', 'K', 'Cl', 'Hb', 'TropI', 'CXR',\n",
            "       'ECG', 'LVIDd', 'FS', 'LVIDs', 'LVEF', 'RWMA', 'LAV', 'MI', 'ACS',\n",
            "       'Wall', 'Thrombolysis', 'ICT', 'IRT', 'MR', 'EA', 'DT', 'MPI', 'RR',\n",
            "       'Chest_pain', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP', 'HF'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(dataf.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fN9U71HZ8NGY",
      "metadata": {
        "id": "fN9U71HZ8NGY"
      },
      "outputs": [],
      "source": [
        "# Exclude the target column from numeric columns\n",
        "numeric_cols = [col for col in X_train.columns if col != 'HF_1']\n",
        "\n",
        "# Scaling numerical features (avoiding data leakage)\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ykzC3Km38ue0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ykzC3Km38ue0",
        "outputId": "9b3930c9-4d61-4aea-c5bc-df3c1f6e74c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation of numerical features with HF:\n",
            " HF              1.000000\n",
            "RWMA            0.555569\n",
            "NYHA            0.547427\n",
            "MI              0.523669\n",
            "Chest_pain      0.517996\n",
            "LVIDs           0.487436\n",
            "Wall            0.412381\n",
            "ACS             0.404052\n",
            "ECG             0.402677\n",
            "LVIDd           0.396085\n",
            "CXR             0.349754\n",
            "MR              0.300189\n",
            "Age             0.218864\n",
            "TropI           0.213556\n",
            "BNP             0.204609\n",
            "IRT             0.204211\n",
            "HR              0.201229\n",
            "RBS             0.190930\n",
            "RR              0.158264\n",
            "DM              0.148409\n",
            "HTN             0.148131\n",
            "TC              0.144203\n",
            "DL              0.141524\n",
            "Creatinine      0.126285\n",
            "Sex             0.123122\n",
            "LDLc            0.122968\n",
            "Smoker          0.111850\n",
            "Thrombolysis    0.110787\n",
            "ICT             0.110719\n",
            "MPI             0.099581\n",
            "HbA1C           0.075143\n",
            "LAV             0.050025\n",
            "TG              0.049793\n",
            "HDLc            0.033168\n",
            "K               0.010638\n",
            "Cl              0.004967\n",
            "EA             -0.007328\n",
            "Na             -0.031671\n",
            "Hb             -0.085204\n",
            "BA             -0.113276\n",
            "BMI            -0.129587\n",
            "DT             -0.291077\n",
            "LVEF           -0.510219\n",
            "FS             -0.605061\n",
            "Name: HF, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert HF to numeric (if not already)\n",
        "dataf['HF'] = pd.to_numeric(dataf['HF'])\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = dataf.corr()\n",
        "\n",
        "# Extract correlations with HF\n",
        "hf_correlation = correlation_matrix['HF'].sort_values(ascending=False)\n",
        "\n",
        "# Display correlations\n",
        "print(\"Correlation of numerical features with HF:\\n\", hf_correlation)\n",
        "\n",
        "# Plot heatmap for better visualization\n",
        "plt.figure(figsize=(50, 20))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4U7qs3ZQfddV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4U7qs3ZQfddV",
        "outputId": "5e87fe97-3833-423e-9f2f-1b26ee4c7a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Mean (HF=1)  Mean (HF=0)  Difference\n",
            "BNP          124.700730    40.225664   84.475066\n",
            "TC           181.211679   167.694690   13.516989\n",
            "TG           175.288321   165.283186   10.005135\n",
            "LDLc         117.620438   108.327434    9.293004\n",
            "IRT          101.799270    93.473451    8.325819\n",
            "LVIDs         39.580292    31.283186    8.297106\n",
            "TropI         15.375964     7.830193    7.545771\n",
            "HR            83.430657    77.402655    6.028002\n",
            "LVIDd         51.452555    45.575221    5.877334\n",
            "Age           58.051095    52.473451    5.577644\n",
            "ICT           89.675182    85.827434    3.847749\n",
            "RBS            8.840474     7.484956    1.355519\n",
            "RR            20.952555    19.911504    1.041050\n",
            "LAV           35.529197    34.615044    0.914153\n",
            "HDLc          34.740876    34.331858    0.409018\n",
            "Creatinine     1.478796     1.154735    0.324061\n",
            "HbA1C          6.395255     6.128319    0.266937\n",
            "Cl           101.631387   101.579646    0.051741\n",
            "MPI            0.234745     0.199602    0.035143\n",
            "K              3.918577     3.911018    0.007559\n",
            "EA             1.102080     1.111150   -0.009070\n",
            "Na           138.357664   138.606195   -0.248530\n",
            "Hb            12.349635    12.600885   -0.251250\n",
            "BMI           24.902701    25.955841   -1.053140\n",
            "FS            22.003650    31.141593   -9.137943\n",
            "LVEF          43.507299    55.597345  -12.090046\n",
            "DT           142.784672   167.792035  -25.007364\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Split the dataset into HF=1 (Heart Failure) and HF=0 (No Heart Failure)\n",
        "hf_1 = dataf[dataf['HF'] == 1]\n",
        "hf_0 = dataf[dataf['HF'] == 0] # Use 'HF_1' and check for value 0\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "# Compute mean difference for each numerical variable\n",
        "numerical_features = dataf.select_dtypes(include=['float64']).columns\n",
        "mean_diff = pd.DataFrame({\n",
        "    'Mean (HF=1)': hf_1[numerical_features].mean(),\n",
        "    'Mean (HF=0)': hf_0[numerical_features].mean(),\n",
        "    'Difference': hf_1[numerical_features].mean() - hf_0[numerical_features].mean()\n",
        "})\n",
        "\n",
        "# Sort features by difference (absolute value)\n",
        "mean_diff = mean_diff.sort_values(by='Difference', ascending=False)\n",
        "\n",
        "# Display top features with highest differences\n",
        "print(mean_diff.head(44))\n",
        "\n",
        "# Plot the top features with highest differences\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=mean_diff['Difference'].head(44), y=mean_diff.index[:44], palette='viridis')\n",
        "plt.axvline(x=0, color='black', linestyle='--')  # Reference line at zero\n",
        "plt.title('Top Numerical Features Differentiating HF=1 vs HF=0')\n",
        "plt.xlabel('Mean Difference (HF=1 - HF=0)')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-LOR6lv58uba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-LOR6lv58uba",
        "outputId": "a79ddba0-94d7-42a7-e7b5-edf2caab92db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Mean (HF=1)  Mean (HF=0)  Difference\n",
            "BNP          124.700730    40.225664   84.475066\n",
            "TC           181.211679   167.694690   13.516989\n",
            "TG           175.288321   165.283186   10.005135\n",
            "LDLc         117.620438   108.327434    9.293004\n",
            "IRT          101.799270    93.473451    8.325819\n",
            "LVIDs         39.580292    31.283186    8.297106\n",
            "TropI         15.375964     7.830193    7.545771\n",
            "HR            83.430657    77.402655    6.028002\n",
            "LVIDd         51.452555    45.575221    5.877334\n",
            "Age           58.051095    52.473451    5.577644\n",
            "ICT           89.675182    85.827434    3.847749\n",
            "RBS            8.840474     7.484956    1.355519\n",
            "RR            20.952555    19.911504    1.041050\n",
            "LAV           35.529197    34.615044    0.914153\n",
            "HDLc          34.740876    34.331858    0.409018\n",
            "Creatinine     1.478796     1.154735    0.324061\n",
            "HbA1C          6.395255     6.128319    0.266937\n",
            "Cl           101.631387   101.579646    0.051741\n",
            "MPI            0.234745     0.199602    0.035143\n",
            "K              3.918577     3.911018    0.007559\n",
            "EA             1.102080     1.111150   -0.009070\n",
            "Na           138.357664   138.606195   -0.248530\n",
            "Hb            12.349635    12.600885   -0.251250\n",
            "BMI           24.902701    25.955841   -1.053140\n",
            "FS            22.003650    31.141593   -9.137943\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Split the dataset into HF=1 (Heart Failure) and HF=0 (No Heart Failure)\n",
        "hf_1 = dataf[dataf['HF'] == 1]\n",
        "hf_0 = dataf[dataf['HF'] == 0] # Use 'HF_1' and check for value 0\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "# Compute mean difference for each numerical variable\n",
        "numerical_features = dataf.select_dtypes(include=['float64']).columns\n",
        "mean_diff = pd.DataFrame({\n",
        "    'Mean (HF=1)': hf_1[numerical_features].mean(),\n",
        "    'Mean (HF=0)': hf_0[numerical_features].mean(),\n",
        "    'Difference': hf_1[numerical_features].mean() - hf_0[numerical_features].mean()\n",
        "})\n",
        "\n",
        "# Sort features by difference (absolute value)\n",
        "mean_diff = mean_diff.sort_values(by='Difference', ascending=False)\n",
        "\n",
        "# Display top features with highest differences\n",
        "print(mean_diff.head(25))\n",
        "\n",
        "# Plot the top features with highest differences\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=mean_diff['Difference'].head(10), y=mean_diff.index[:10], palette='viridis')\n",
        "plt.axvline(x=0, color='black', linestyle='--')  # Reference line at zero\n",
        "plt.title('Top Numerical Features Differentiating HF=1 vs HF=0')\n",
        "plt.xlabel('Mean Difference (HF=1 - HF=0)')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tdB6BoT48uYl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdB6BoT48uYl",
        "outputId": "03020fa8-33f0-4a29-a133-541a3bb63442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Mean (HF=1)  Mean (HF=0)  Difference\n",
            "BNP          124.700730    40.225664   84.475066\n",
            "TC           181.211679   167.694690   13.516989\n",
            "TG           175.288321   165.283186   10.005135\n",
            "LDLc         117.620438   108.327434    9.293004\n",
            "IRT          101.799270    93.473451    8.325819\n",
            "LVIDs         39.580292    31.283186    8.297106\n",
            "TropI         15.375964     7.830193    7.545771\n",
            "HR            83.430657    77.402655    6.028002\n",
            "LVIDd         51.452555    45.575221    5.877334\n",
            "Age           58.051095    52.473451    5.577644\n",
            "ICT           89.675182    85.827434    3.847749\n",
            "RBS            8.840474     7.484956    1.355519\n",
            "RR            20.952555    19.911504    1.041050\n",
            "LAV           35.529197    34.615044    0.914153\n",
            "HDLc          34.740876    34.331858    0.409018\n",
            "Creatinine     1.478796     1.154735    0.324061\n",
            "HbA1C          6.395255     6.128319    0.266937\n",
            "Cl           101.631387   101.579646    0.051741\n",
            "MPI            0.234745     0.199602    0.035143\n",
            "K              3.918577     3.911018    0.007559\n",
            "EA             1.102080     1.111150   -0.009070\n",
            "Na           138.357664   138.606195   -0.248530\n",
            "Hb            12.349635    12.600885   -0.251250\n",
            "BMI           24.902701    25.955841   -1.053140\n",
            "FS            22.003650    31.141593   -9.137943\n",
            "LVEF          43.507299    55.597345  -12.090046\n",
            "DT           142.784672   167.792035  -25.007364\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your DataFrame 'dataf'\n",
        "\n",
        "# Split the dataset into HF=1 (Heart Failure) and HF=0 (No Heart Failure)\n",
        "hf_1 = dataf[dataf['HF'] == 1]\n",
        "hf_0 = dataf[dataf['HF'] == 0]  # Use 'HF_1' and check for value 0\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "# Compute mean difference for each numerical variable\n",
        "numerical_features = dataf.select_dtypes(include=['float64']).columns\n",
        "num_diff = pd.DataFrame({  # Assign the DataFrame to num_diff here\n",
        "    'Mean (HF=1)': hf_1[numerical_features].mean(),\n",
        "    'Mean (HF=0)': hf_0[numerical_features].mean(),\n",
        "    'Difference': hf_1[numerical_features].mean() - hf_0[numerical_features].mean()\n",
        "})\n",
        "\n",
        "# Sort by absolute difference (strongest differences at the top)\n",
        "num_diff = num_diff.sort_values(by=\"Difference\", ascending=False)\n",
        "\n",
        "# Display the full numeric variable comparison\n",
        "print(num_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ADXmrcR39BaV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "ADXmrcR39BaV",
        "outputId": "f93d8490-6974-4bbd-9ccb-b6d6846208b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Selected Important Features Based on Variance Threshold:\n",
            "['Age', 'BMI', 'NYHA', 'HR', 'RBS', 'HbA1C', 'Creatinine', 'Na', 'Cl', 'Hb', 'TropI', 'LVIDd', 'FS', 'LVIDs', 'LVEF', 'LAV', 'ICT', 'IRT', 'DT', 'RR', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP']\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your original dataset, and 'selected_features' is already defined\n",
        "# Also assuming 'feature_variances' is already calculated\n",
        "\n",
        "# Calculate the variance for each feature in the dataset\n",
        "# Select only numeric columns before calculating variance\n",
        "feature_variances = pd.DataFrame({'Feature': dataf.select_dtypes(include=[np.number]).columns,\n",
        "                                   'Variance': dataf.select_dtypes(include=[np.number]).var()})\n",
        "\n",
        "# Apply the variance threshold (for example, threshold = 0.80)\n",
        "threshold = 0.50\n",
        "selected_var = feature_variances[feature_variances['Variance'] >= threshold]\n",
        "\n",
        "# Show selected important features based on the variance threshold\n",
        "print(\"\\nSelected Important Features Based on Variance Threshold:\")\n",
        "print(list(selected_var['Feature']))\n",
        "\n",
        "# Create a bar plot of the selected features based on their variance\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Variance\", y=\"Feature\", data=selected_var, palette=\"Blues\")\n",
        "\n",
        "# Labeling the plot\n",
        "plt.xlabel(\"Variance\")\n",
        "plt.ylabel(\"Feature Name\")\n",
        "plt.title(f\"Selected Features Based on Variance Threshold ({threshold})\")\n",
        "plt.tight_layout()  # Adjust layout for better spacing\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8vvekcv9PTL",
      "metadata": {
        "id": "m8vvekcv9PTL"
      },
      "source": [
        "### SHAP analysis for important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1816c0f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.47.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from shap) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from shap) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /opt/homebrew/lib/python3.10/site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from shap) (24.2)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Using cached slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba>=0.54 in /opt/homebrew/lib/python3.10/site-packages (from shap) (0.61.0)\n",
            "Collecting cloudpickle (from shap)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: typing-extensions in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from shap) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/homebrew/lib/python3.10/site-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Downloading shap-0.47.1-cp310-cp310-macosx_11_0_arm64.whl (491 kB)\n",
            "Using cached slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: slicer, cloudpickle, shap\n",
            "Successfully installed cloudpickle-3.1.1 shap-0.47.1 slicer-0.0.8\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "juRwOE6fyj_v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "juRwOE6fyj_v",
        "outputId": "5e64a436-f8cf-47f6-88c0-92691e9c711d"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get feature names directly from the model\n",
        "feature_names = models['LightGBM'].feature_names_in_\n",
        "\n",
        "# Create a DataFrame for SHAP values\n",
        "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "# Create the SHAP explainer\n",
        "explainer = shap.Explainer(models['LightGBM'])\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_values = explainer(X_test_df)\n",
        "# Generate the summary plot for top 30 features\n",
        "shap.summary_plot(shap_values[:, :37], X_test_df.iloc[:, :37])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qejShF54y7TZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qejShF54y7TZ",
        "outputId": "c352f742-f0b0-4025-c812-d3425d54bd4b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# shap.importance_plot(shap_values, max_display=30)  # Line causing the error\n",
        "shap.plots.bar(shap_values, max_display=37)  # Use shap.plots.bar instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_7aS8Nj4D4TA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7aS8Nj4D4TA",
        "outputId": "c50f8efd-55e7-4308-90a6-d1b26cb07a45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Age', 'Sex', 'BMI', 'NYHA', 'HR', 'HTN', 'DM', 'Smoker', 'DL', 'BA',\n",
              "       'RBS', 'HbA1C', 'Creatinine', 'Na', 'K', 'Cl', 'Hb', 'TropI', 'CXR',\n",
              "       'ECG', 'LVIDd', 'FS', 'LVIDs', 'LVEF', 'RWMA', 'LAV', 'MI', 'ACS',\n",
              "       'Wall', 'Thrombolysis', 'ICT', 'IRT', 'MR', 'EA', 'DT', 'MPI', 'RR',\n",
              "       'Chest_pain', 'TC', 'LDLc', 'HDLc', 'TG', 'BNP', 'HF'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mfhL9wc4s5DK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfhL9wc4s5DK",
        "outputId": "fdc067f1-1992-4540-88a5-84671c66ff93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 44 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Age           500 non-null    float64\n",
            " 1   Sex           500 non-null    int64  \n",
            " 2   BMI           500 non-null    float64\n",
            " 3   NYHA          500 non-null    int64  \n",
            " 4   HR            500 non-null    float64\n",
            " 5   HTN           500 non-null    int64  \n",
            " 6   DM            500 non-null    int64  \n",
            " 7   Smoker        500 non-null    int64  \n",
            " 8   DL            500 non-null    int64  \n",
            " 9   BA            500 non-null    int64  \n",
            " 10  RBS           500 non-null    float64\n",
            " 11  HbA1C         500 non-null    float64\n",
            " 12  Creatinine    500 non-null    float64\n",
            " 13  Na            500 non-null    float64\n",
            " 14  K             500 non-null    float64\n",
            " 15  Cl            500 non-null    float64\n",
            " 16  Hb            500 non-null    float64\n",
            " 17  TropI         500 non-null    float64\n",
            " 18  CXR           500 non-null    int64  \n",
            " 19  ECG           500 non-null    object \n",
            " 20  LVIDd         500 non-null    float64\n",
            " 21  FS            500 non-null    float64\n",
            " 22  LVIDs         500 non-null    float64\n",
            " 23  LVEF          500 non-null    float64\n",
            " 24  RWMA          500 non-null    int64  \n",
            " 25  LAV           500 non-null    float64\n",
            " 26  MI            500 non-null    int64  \n",
            " 27  ACS           500 non-null    object \n",
            " 28  Wall          500 non-null    object \n",
            " 29  Thrombolysis  500 non-null    object \n",
            " 30  ICT           500 non-null    float64\n",
            " 31  IRT           500 non-null    float64\n",
            " 32  MR            500 non-null    int64  \n",
            " 33  EA            500 non-null    float64\n",
            " 34  DT            500 non-null    float64\n",
            " 35  MPI           500 non-null    float64\n",
            " 36  RR            500 non-null    float64\n",
            " 37  Chest_pain    500 non-null    int64  \n",
            " 38  TC            500 non-null    float64\n",
            " 39  LDLc          500 non-null    float64\n",
            " 40  HDLc          500 non-null    float64\n",
            " 41  TG            500 non-null    float64\n",
            " 42  BNP           500 non-null    float64\n",
            " 43  HF            500 non-null    int64  \n",
            "dtypes: float64(27), int64(13), object(4)\n",
            "memory usage: 172.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Oj0bry00yJEg",
      "metadata": {
        "id": "Oj0bry00yJEg"
      },
      "source": [
        "## Features to drop by Based on Variance Threshold ,SHAP analysis and  Domain Expert and create a new data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vJbYamVBTFrv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJbYamVBTFrv",
        "outputId": "b2714fd5-ddac-477f-b7b1-562aea586091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped features successfully. New shape of dataset:\n",
            "Training Data: (400, 35), Testing Data: (100, 35)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert X_train and X_test to DataFrames if they are NumPy arrays\n",
        "if isinstance(X_train, np.ndarray):\n",
        "    X_train = pd.DataFrame(X_train, columns=feature_names)\n",
        "\n",
        "if isinstance(X_test, np.ndarray):\n",
        "    X_test = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "# List of features to drop\n",
        "features_to_drop = [\"BA\", \"HbA1C\", \"Na\", \"K\", \"Cl\", \"Hb\", \"MPI\", \"HDLc\"]\n",
        "\n",
        "# Drop features from the dataset\n",
        "X_train.drop(columns=features_to_drop, inplace=True, errors='ignore')  # Ignore errors if feature not found\n",
        "X_test.drop(columns=features_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "print(\"Dropped features successfully. New shape of dataset:\")\n",
        "print(f\"Training Data: {X_train.shape}, Testing Data: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NexxM5bTO4Yl",
      "metadata": {
        "id": "NexxM5bTO4Yl"
      },
      "source": [
        "### Evaluate models and store results to find best 3 Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RwbOQhcJTFov",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwbOQhcJTFov",
        "outputId": "6f192f38-0f37-4f5c-c90c-25886ccc147a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sorted Results by Accuracy:\n",
            "                           Model  Accuracy  Precision (Class 0)  \\\n",
            "11                      LightGBM      0.85             0.875000   \n",
            "4                  Random Forest      0.84             0.853659   \n",
            "10        Extra Trees Classifier      0.84             0.871795   \n",
            "6               Ridge Classifier      0.83             0.850000   \n",
            "9              Gradient Boosting      0.83             0.850000   \n",
            "7   Linear Discriminant Analysis      0.81             0.842105   \n",
            "13                       XGBoost      0.81             0.825000   \n",
            "14                      CatBoost      0.81             0.933333   \n",
            "0            Logistic Regression      0.79             0.785714   \n",
            "3                  Decision Tree      0.79             0.785714   \n",
            "5         Support Vector Machine      0.79             0.815789   \n",
            "12  Multi-Layer Perceptron (MLP)      0.79             0.800000   \n",
            "2                    Naive Bayes      0.76             0.783784   \n",
            "8                       AdaBoost      0.76             0.744186   \n",
            "1            K-Nearest Neighbors      0.75             0.727273   \n",
            "\n",
            "    Recall (Class 0)  F1 Score (Class 0)  Precision (Class 1)  \\\n",
            "11          0.777778            0.823529             0.833333   \n",
            "4           0.777778            0.813953             0.830508   \n",
            "10          0.755556            0.809524             0.819672   \n",
            "6           0.755556            0.800000             0.816667   \n",
            "9           0.755556            0.800000             0.816667   \n",
            "7           0.711111            0.771084             0.790323   \n",
            "13          0.733333            0.776471             0.800000   \n",
            "14          0.622222            0.746667             0.757143   \n",
            "0           0.733333            0.758621             0.793103   \n",
            "3           0.733333            0.758621             0.793103   \n",
            "5           0.688889            0.746988             0.774194   \n",
            "12          0.711111            0.752941             0.783333   \n",
            "2           0.644444            0.707317             0.746032   \n",
            "8           0.711111            0.727273             0.771930   \n",
            "1           0.711111            0.719101             0.767857   \n",
            "\n",
            "    Recall (Class 1)  F1 Score (Class 1)  Precision (Class macro avg)  \\\n",
            "11          0.909091            0.869565                     0.854167   \n",
            "4           0.890909            0.859649                     0.842084   \n",
            "10          0.909091            0.862069                     0.845734   \n",
            "6           0.890909            0.852174                     0.833333   \n",
            "9           0.890909            0.852174                     0.833333   \n",
            "7           0.890909            0.837607                     0.816214   \n",
            "13          0.872727            0.834783                     0.812500   \n",
            "14          0.963636            0.848000                     0.845238   \n",
            "0           0.836364            0.814159                     0.789409   \n",
            "3           0.836364            0.814159                     0.789409   \n",
            "5           0.872727            0.820513                     0.794992   \n",
            "12          0.854545            0.817391                     0.791667   \n",
            "2           0.854545            0.796610                     0.764908   \n",
            "8           0.800000            0.785714                     0.758058   \n",
            "1           0.781818            0.774775                     0.747565   \n",
            "\n",
            "    Recall (Class macro avg)  F1 Score (Class macro avg)  \\\n",
            "11                  0.843434                    0.846547   \n",
            "4                   0.834343                    0.836801   \n",
            "10                  0.832323                    0.835796   \n",
            "6                   0.823232                    0.826087   \n",
            "9                   0.823232                    0.826087   \n",
            "7                   0.801010                    0.804346   \n",
            "13                  0.803030                    0.805627   \n",
            "14                  0.792929                    0.797333   \n",
            "0                   0.784848                    0.786390   \n",
            "3                   0.784848                    0.786390   \n",
            "5                   0.780808                    0.783750   \n",
            "12                  0.782828                    0.785166   \n",
            "2                   0.749495                    0.751964   \n",
            "8                   0.755556                    0.756494   \n",
            "1                   0.746465                    0.746938   \n",
            "\n",
            "    Precision (Class weighted avg)  Recall (Class weighted avg)  \\\n",
            "11                        0.852083                         0.85   \n",
            "4                         0.840926                         0.84   \n",
            "10                        0.843127                         0.84   \n",
            "6                         0.831667                         0.83   \n",
            "9                         0.831667                         0.83   \n",
            "7                         0.813625                         0.81   \n",
            "13                        0.811250                         0.81   \n",
            "14                        0.836429                         0.81   \n",
            "0                         0.789778                         0.79   \n",
            "3                         0.789778                         0.79   \n",
            "5                         0.792912                         0.79   \n",
            "12                        0.790833                         0.79   \n",
            "2                         0.763020                         0.76   \n",
            "8                         0.759445                         0.76   \n",
            "1                         0.749594                         0.75   \n",
            "\n",
            "    F1 Score (Class weighted avg)  \n",
            "11                       0.848849  \n",
            "4                        0.839086  \n",
            "10                       0.838424  \n",
            "6                        0.828696  \n",
            "9                        0.828696  \n",
            "7                        0.807672  \n",
            "13                       0.808542  \n",
            "14                       0.802400  \n",
            "0                        0.789167  \n",
            "3                        0.789167  \n",
            "5                        0.787427  \n",
            "12                       0.788389  \n",
            "2                        0.756428  \n",
            "8                        0.759416  \n",
            "1                        0.749722  \n",
            "\n",
            "Top 3 Best Models Based on Overall Performance:\n",
            "\n",
            "                           Model  Accuracy  Precision (Class 0)  \\\n",
            "11                      LightGBM      0.85             0.875000   \n",
            "4                  Random Forest      0.84             0.853659   \n",
            "10        Extra Trees Classifier      0.84             0.871795   \n",
            "6               Ridge Classifier      0.83             0.850000   \n",
            "9              Gradient Boosting      0.83             0.850000   \n",
            "7   Linear Discriminant Analysis      0.81             0.842105   \n",
            "13                       XGBoost      0.81             0.825000   \n",
            "14                      CatBoost      0.81             0.933333   \n",
            "0            Logistic Regression      0.79             0.785714   \n",
            "3                  Decision Tree      0.79             0.785714   \n",
            "5         Support Vector Machine      0.79             0.815789   \n",
            "12  Multi-Layer Perceptron (MLP)      0.79             0.800000   \n",
            "2                    Naive Bayes      0.76             0.783784   \n",
            "8                       AdaBoost      0.76             0.744186   \n",
            "1            K-Nearest Neighbors      0.75             0.727273   \n",
            "\n",
            "    Recall (Class 0)  F1 Score (Class 0)  Precision (Class 1)  \\\n",
            "11          0.777778            0.823529             0.833333   \n",
            "4           0.777778            0.813953             0.830508   \n",
            "10          0.755556            0.809524             0.819672   \n",
            "6           0.755556            0.800000             0.816667   \n",
            "9           0.755556            0.800000             0.816667   \n",
            "7           0.711111            0.771084             0.790323   \n",
            "13          0.733333            0.776471             0.800000   \n",
            "14          0.622222            0.746667             0.757143   \n",
            "0           0.733333            0.758621             0.793103   \n",
            "3           0.733333            0.758621             0.793103   \n",
            "5           0.688889            0.746988             0.774194   \n",
            "12          0.711111            0.752941             0.783333   \n",
            "2           0.644444            0.707317             0.746032   \n",
            "8           0.711111            0.727273             0.771930   \n",
            "1           0.711111            0.719101             0.767857   \n",
            "\n",
            "    Recall (Class 1)  F1 Score (Class 1)  Precision (Class macro avg)  \\\n",
            "11          0.909091            0.869565                     0.854167   \n",
            "4           0.890909            0.859649                     0.842084   \n",
            "10          0.909091            0.862069                     0.845734   \n",
            "6           0.890909            0.852174                     0.833333   \n",
            "9           0.890909            0.852174                     0.833333   \n",
            "7           0.890909            0.837607                     0.816214   \n",
            "13          0.872727            0.834783                     0.812500   \n",
            "14          0.963636            0.848000                     0.845238   \n",
            "0           0.836364            0.814159                     0.789409   \n",
            "3           0.836364            0.814159                     0.789409   \n",
            "5           0.872727            0.820513                     0.794992   \n",
            "12          0.854545            0.817391                     0.791667   \n",
            "2           0.854545            0.796610                     0.764908   \n",
            "8           0.800000            0.785714                     0.758058   \n",
            "1           0.781818            0.774775                     0.747565   \n",
            "\n",
            "    Recall (Class macro avg)  F1 Score (Class macro avg)  \\\n",
            "11                  0.843434                    0.846547   \n",
            "4                   0.834343                    0.836801   \n",
            "10                  0.832323                    0.835796   \n",
            "6                   0.823232                    0.826087   \n",
            "9                   0.823232                    0.826087   \n",
            "7                   0.801010                    0.804346   \n",
            "13                  0.803030                    0.805627   \n",
            "14                  0.792929                    0.797333   \n",
            "0                   0.784848                    0.786390   \n",
            "3                   0.784848                    0.786390   \n",
            "5                   0.780808                    0.783750   \n",
            "12                  0.782828                    0.785166   \n",
            "2                   0.749495                    0.751964   \n",
            "8                   0.755556                    0.756494   \n",
            "1                   0.746465                    0.746938   \n",
            "\n",
            "    Precision (Class weighted avg)  Recall (Class weighted avg)  \\\n",
            "11                        0.852083                         0.85   \n",
            "4                         0.840926                         0.84   \n",
            "10                        0.843127                         0.84   \n",
            "6                         0.831667                         0.83   \n",
            "9                         0.831667                         0.83   \n",
            "7                         0.813625                         0.81   \n",
            "13                        0.811250                         0.81   \n",
            "14                        0.836429                         0.81   \n",
            "0                         0.789778                         0.79   \n",
            "3                         0.789778                         0.79   \n",
            "5                         0.792912                         0.79   \n",
            "12                        0.790833                         0.79   \n",
            "2                         0.763020                         0.76   \n",
            "8                         0.759445                         0.76   \n",
            "1                         0.749594                         0.75   \n",
            "\n",
            "    F1 Score (Class weighted avg)  \n",
            "11                       0.848849  \n",
            "4                        0.839086  \n",
            "10                       0.838424  \n",
            "6                        0.828696  \n",
            "9                        0.828696  \n",
            "7                        0.807672  \n",
            "13                       0.808542  \n",
            "14                       0.802400  \n",
            "0                        0.789167  \n",
            "3                        0.789167  \n",
            "5                        0.787427  \n",
            "12                       0.788389  \n",
            "2                        0.756428  \n",
            "8                        0.759416  \n",
            "1                        0.749722  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Set global seed for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Define models with fixed random_state\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "models = {\n",
        "    # 🔹 Logistic Regression: Strong regularization for better generalization\n",
        "    'Logistic Regression': LogisticRegression(\n",
        "        C=0.3, solver='liblinear', penalty='l1', class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 K-Nearest Neighbors: Reducing overfitting with distance-based weighting\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(\n",
        "        n_neighbors=5, weights='distance', algorithm='ball_tree', leaf_size=20, p=2\n",
        "    ),\n",
        "\n",
        "    # 🔹 Naive Bayes: Adjusted for better probability estimation\n",
        "    'Naive Bayes': GaussianNB(var_smoothing=1e-8),\n",
        "\n",
        "    # 🔹 Decision Tree: More depth and splitting to capture complex patterns\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        criterion='entropy', max_depth=20, min_samples_split=3, min_samples_leaf=2, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Random Forest: More trees & depth for higher accuracy\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=300, max_depth=15, min_samples_split=3, min_samples_leaf=1,\n",
        "        class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Support Vector Machine: Higher C, balanced class weights\n",
        "    'Support Vector Machine': SVC(\n",
        "        C=5.0, kernel='rbf', gamma='scale', probability=True, class_weight='balanced', random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Ridge Classifier: Optimized regularization for stability\n",
        "    'Ridge Classifier': RidgeClassifier(alpha=0.3, class_weight='balanced'),\n",
        "\n",
        "    # 🔹 Quadratic Discriminant Analysis: Optimized for stability\n",
        "    #'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(reg_param=0.03),\n",
        "\n",
        "    # 🔹 Linear Discriminant Analysis: Optimized shrinkage\n",
        "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'),\n",
        "\n",
        "    # 🔹 AdaBoost: More estimators & lower learning rate\n",
        "    'AdaBoost': AdaBoostClassifier(\n",
        "        n_estimators=200, learning_rate=0.05, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Gradient Boosting: Lower learning rate, more estimators\n",
        "    'Gradient Boosting': GradientBoostingClassifier(\n",
        "        learning_rate=0.03, n_estimators=250, max_depth=10, min_samples_split=3,\n",
        "        min_samples_leaf=2, subsample=0.85, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Extra Trees Classifier: Higher estimators for robustness\n",
        "    'Extra Trees Classifier': ExtraTreesClassifier(\n",
        "        n_estimators=300, max_depth=12, min_samples_split=4, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 LightGBM: Optimized for best recall & precision\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        colsample_bytree=0.9, learning_rate=0.03, max_depth=20, min_child_samples=5,\n",
        "        n_estimators=250, num_leaves=90, subsample=0.85, class_weight='balanced',verbose=-1, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 Multi-Layer Perceptron (MLP): More layers & epochs for better feature learning\n",
        "    'Multi-Layer Perceptron (MLP)': MLPClassifier(\n",
        "        hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', alpha=0.0001,\n",
        "        batch_size=16, learning_rate='adaptive', max_iter=500, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 XGBoost: Tuned for high performance\n",
        "    'XGBoost': XGBClassifier(\n",
        "        colsample_bytree=0.8, learning_rate=0.03, max_depth=12, min_child_weight=4,\n",
        "        n_estimators=250, subsample=0.85, gamma=0.1, reg_alpha=0.1, reg_lambda=0.1,\n",
        "        scale_pos_weight=1, random_state=SEED\n",
        "    ),\n",
        "\n",
        "    # 🔹 CatBoost: Tuned for medical applications\n",
        "    'CatBoost': CatBoostClassifier(\n",
        "        iterations=250, learning_rate=0.03, depth=14, min_data_in_leaf=5,\n",
        "        subsample=0.85, l2_leaf_reg=3, class_weights=[1, 4], random_state=SEED, verbose=0\n",
        "    )\n",
        "}\n",
        "\n",
        "# Evaluate models and store results in a DataFrame\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Convert y_test and y_pred to integers before calculating accuracy\n",
        "        accuracy = accuracy_score(y_test.astype(int), y_pred.astype(int))\n",
        "\n",
        "        # Get classification report for multi-class classification\n",
        "        report = classification_report(y_test.astype(int), y_pred.astype(int), output_dict=True)\n",
        "\n",
        "        # Collect results dynamically for each class\n",
        "        model_result = {\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "        }\n",
        "\n",
        "        # Add Precision, Recall, F1 score for each class dynamically\n",
        "        for label in report.keys():\n",
        "            if label != 'accuracy':  # Exclude the accuracy key\n",
        "                model_result[f'Precision (Class {label})'] = report[label]['precision']\n",
        "                model_result[f'Recall (Class {label})'] = report[label]['recall']\n",
        "                model_result[f'F1 Score (Class {label})'] = report[label]['f1-score']\n",
        "\n",
        "        results.append(model_result)\n",
        "\n",
        "    # Create a DataFrame from results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "# Run evaluation with models\n",
        "results_df = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Sort results by accuracy\n",
        "sorted_results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "# Display the sorted results\n",
        "print(\"\\nSorted Results by Accuracy:\")\n",
        "print(sorted_results_df)\n",
        "\n",
        "# Print the best three models\n",
        "print(\"\\nTop 3 Best Models Based on Overall Performance:\\n\")\n",
        "print(sorted_results_df.head(15))\n",
        "\n",
        "# Store best models\n",
        "best_models = sorted_results_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5VSOiqCoKMVp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "5VSOiqCoKMVp",
        "outputId": "0093b84f-c9ba-4c43-a761-2dad8a609081"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to create a comparison plot with line graphs for all metrics in one plot\n",
        "def plot_model_comparison_all_metrics(sorted_results_df):\n",
        "    # Set the plot style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Prepare the data for plotting\n",
        "    metrics = [\n",
        "        'Accuracy',\n",
        "        'Precision (Class macro avg)',\n",
        "        'Recall (Class macro avg)',\n",
        "        'F1 Score (Class macro avg)',\n",
        "        'Precision (Class weighted avg)',\n",
        "        'Recall (Class weighted avg)',\n",
        "        'F1 Score (Class weighted avg)'\n",
        "    ]\n",
        "\n",
        "    # Create the figure and axis for plotting\n",
        "    plt.figure(figsize=(14, 8))  # Adjusted plot size\n",
        "\n",
        "    # Define a color palette for distinct line colors\n",
        "    color_palette = sns.color_palette(\"Set2\", len(metrics))  # Choose a different color for each metric\n",
        "\n",
        "    # Iterate through each metric and plot its value\n",
        "    for i, metric in enumerate(metrics):\n",
        "        sns.lineplot(x='Model', y=metric, data=sorted_results_df, label=metric,\n",
        "                     marker='o', linewidth=2, color=color_palette[i])\n",
        "\n",
        "    # Set the title and labels with larger fonts\n",
        "    plt.title('Comparison of Metrics for Each Model (Before Cross-Validation and Hyperamiter ,With Feature Selection)', fontsize=18)\n",
        "    plt.xlabel('Model', fontsize=16)\n",
        "    plt.ylabel('Score', fontsize=16)\n",
        "    plt.xticks(rotation=90, fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend(title='Metrics', fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_model_comparison_all_metrics(sorted_results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KHJhsPffRa9n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "KHJhsPffRa9n",
        "outputId": "0d0e34ea-1c65-40dd-b7bc-7cadac2983de"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to create a bar chart comparing accuracy\n",
        "def plot_accuracy_comparison(sorted_results_df):\n",
        "    # Set the plot style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Create the figure and axis for plotting\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create the bar plot for accuracy\n",
        "    sns.barplot(x='Model', y='Accuracy', data=sorted_results_df, palette='Blues_r')\n",
        "\n",
        "    # Set the title and labels\n",
        "    plt.title('Accuracy Comparison of Models', fontsize=16)\n",
        "    plt.xlabel('Model', fontsize=14)\n",
        "    plt.ylabel('Accuracy Score', fontsize=14)\n",
        "    plt.xticks(rotation=90, fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_accuracy_comparison(sorted_results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JV6f33nXWtQr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JV6f33nXWtQr",
        "outputId": "e0398dfc-b1f7-4800-e043-a4e5d05bae2e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to create a bar chart comparing accuracy with percentage labels\n",
        "def plot_accuracy_comparison(sorted_results_df):\n",
        "    # Set the plot style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Create the figure and axis for plotting\n",
        "    plt.figure(figsize=(20, 12))\n",
        "\n",
        "    # Create the bar plot for accuracy\n",
        "    ax = sns.barplot(x='Model', y='Accuracy', data=sorted_results_df, palette='Blues_r')\n",
        "\n",
        "    # Add percentage labels on top of the bars\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height()*100:.1f}%',  # Convert to percentage\n",
        "                    (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Set the title and labels\n",
        "    plt.title('Accuracy Comparison of Models', fontsize=16)\n",
        "    plt.xlabel('Model', fontsize=14)\n",
        "    plt.ylabel('Accuracy Score', fontsize=14)\n",
        "    plt.xticks(rotation=90, fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_accuracy_comparison(sorted_results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vJxp1bjakwql",
      "metadata": {
        "id": "vJxp1bjakwql"
      },
      "source": [
        "#### Confusion matrix for the best 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SOKzdg_Gkedb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SOKzdg_Gkedb",
        "outputId": "77f2e33b-f605-446c-eb39-41a7a215184c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Function to plot confusion matrix for the best models\n",
        "def plot_confusion_matrices(models, X_train, y_train, X_test, y_test, best_models):\n",
        "    for name in best_models['Model']:\n",
        "        model = models[name]\n",
        "\n",
        "        # Fit the model and make predictions\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Generate the confusion matrix\n",
        "        cm = confusion_matrix(y_test.astype(int), y_pred.astype(int))  # Convert to int before calculating\n",
        "\n",
        "        # Plot the confusion matrix\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Class 0\", \"Class 1\"])\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "        plt.title(f\"Confusion Matrix for {name}\")\n",
        "        plt.show()\n",
        "\n",
        "# Call the function to plot confusion matrices for the top 3 models\n",
        "plot_confusion_matrices(models, X_train, y_train, X_test, y_test, best_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GEqD9BjWlDPt",
      "metadata": {
        "id": "GEqD9BjWlDPt"
      },
      "source": [
        "### ROC Curve and calculate AUC for the best 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8nsCYwBhkeaH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "8nsCYwBhkeaH",
        "outputId": "9a3acee7-f16e-4b06-f45b-30d49cd90565"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Function to plot ROC Curve and calculate AUC for the best models\n",
        "def plot_roc_auc(models, X_train, y_train, X_test, y_test, best_models):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for name in best_models['Model']:  # Assuming best_models is a DataFrame with a 'Model' column\n",
        "        model = models[name]\n",
        "\n",
        "        # Fit the model and get probabilities for ROC curve\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Check if the model has predict_proba method before calling it\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
        "        else:\n",
        "            # For models without predict_proba, use decision_function if available\n",
        "            if hasattr(model, 'decision_function'):\n",
        "                y_prob = model.decision_function(X_test)\n",
        "            else:\n",
        "                # If neither predict_proba nor decision_function is available, skip the model\n",
        "                print(f\"Skipping ROC curve for {name} as it does not have predict_proba or decision_function\")\n",
        "                continue\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "    # Plot the random classifier (diagonal line)\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel('False Positive Rate', fontsize=14)\n",
        "    plt.ylabel('True Positive Rate', fontsize=14)\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
        "    plt.legend(loc='lower right', fontsize=12)\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_roc_auc(models, X_train, y_train, X_test, y_test, best_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kCi6vmiVO_rC",
      "metadata": {
        "id": "kCi6vmiVO_rC"
      },
      "source": [
        "## Optimizing Multiple ML Models : Optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4BJU-eqPKTP",
      "metadata": {
        "id": "K4BJU-eqPKTP"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Choose the algorithm to tune\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['Extra Trees Classifier', 'RandomForest', 'LightGBM'])\n",
        "\n",
        "    if classifier_name == 'Extra Trees Classifier':\n",
        "        # Extra Trees Classifier hyperparameters\n",
        "        n_estimators = trial.suggest_int('n_estimators', 1000, 2000)\n",
        "        max_depth = trial.suggest_int('max_depth', 10, 30)\n",
        "        min_samples_split = trial.suggest_int('min_samples_split', 10, 30)\n",
        "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "\n",
        "        model = ExtraTreesClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    elif classifier_name == 'RandomForest':\n",
        "        # Random Forest hyperparameters\n",
        "        n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
        "        max_depth = trial.suggest_int('max_depth', 10, 30)\n",
        "        min_samples_split = trial.suggest_int('min_samples_split', 5, 20)\n",
        "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "        bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            bootstrap=bootstrap,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    elif classifier_name == 'LightGBM':\n",
        "        # LightGBM hyperparameters\n",
        "        boosting_type = trial.suggest_categorical('boosting_type', ['dart'])\n",
        "        n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 0.0001, 0.001)\n",
        "        max_bin = trial.suggest_int('max_bin', 500, 2000)\n",
        "        importance_type = trial.suggest_categorical('importance_type', ['gain'])\n",
        "\n",
        "        model = LGBMClassifier(\n",
        "            boosting_type=boosting_type,\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            max_bin=max_bin,\n",
        "            importance_type=importance_type,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    # Perform cross-validation and return the mean accuracy\n",
        "    score = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa445889",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Using cached optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Using cached alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from optuna) (24.2)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading sqlalchemy-2.0.39-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /opt/homebrew/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /Users/khalid/Library/Python/3.10/lib/python/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/homebrew/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Using cached optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "Using cached alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "Downloading sqlalchemy-2.0.39-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Using cached Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: sqlalchemy, Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1 sqlalchemy-2.0.39\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t2RTPRxkPKMw",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2RTPRxkPKMw",
        "outputId": "7dd9d72e-122b-44ca-8020-e93c85f3bfca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-25 15:14:30,829] A new study created in memory with name: no-name-09afa9d3-440a-4237-bc2c-1d6fd7ea8941\n",
            "[I 2025-03-25 15:14:38,975] Trial 0 finished with value: 0.865 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1656, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 0 with value: 0.865.\n",
            "[I 2025-03-25 15:14:41,189] Trial 1 finished with value: 0.8525 and parameters: {'classifier': 'RandomForest', 'n_estimators': 487, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 12, 'bootstrap': True}. Best is trial 0 with value: 0.865.\n",
            "[I 2025-03-25 15:14:46,285] Trial 2 finished with value: 0.8474999999999999 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1619, 'max_depth': 18, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.865.\n",
            "[I 2025-03-25 15:14:49,112] Trial 3 finished with value: 0.7849999999999999 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 169, 'learning_rate': 0.0006669164880425811, 'max_bin': 1193, 'importance_type': 'gain'}. Best is trial 0 with value: 0.865.\n",
            "[I 2025-03-25 15:14:53,161] Trial 4 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 786, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:09,616] Trial 5 finished with value: 0.8125 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 726, 'learning_rate': 0.00038990282441815963, 'max_bin': 1988, 'importance_type': 'gain'}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:14,488] Trial 6 finished with value: 0.8125 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 272, 'learning_rate': 0.0005218200659535184, 'max_bin': 1644, 'importance_type': 'gain'}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:20,039] Trial 7 finished with value: 0.8525 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1204, 'max_depth': 18, 'min_samples_split': 18, 'min_samples_leaf': 12, 'bootstrap': True}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:24,767] Trial 8 finished with value: 0.8325000000000001 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1511, 'max_depth': 12, 'min_samples_split': 22, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:28,226] Trial 9 finished with value: 0.8150000000000001 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1182, 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 19}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:32,142] Trial 10 finished with value: 0.86 and parameters: {'classifier': 'RandomForest', 'n_estimators': 831, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:39,545] Trial 11 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1404, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:49,651] Trial 12 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1919, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:15:53,922] Trial 13 finished with value: 0.8625 and parameters: {'classifier': 'RandomForest', 'n_estimators': 889, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 4 with value: 0.8700000000000001.\n",
            "[I 2025-03-25 15:16:01,039] Trial 14 finished with value: 0.8875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1328, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:16:03,567] Trial 15 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 521, 'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:16:08,258] Trial 16 finished with value: 0.86 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1091, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 16, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:16:14,645] Trial 17 finished with value: 0.8724999999999999 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1291, 'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:16:18,778] Trial 18 finished with value: 0.8300000000000001 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1342, 'max_depth': 23, 'min_samples_split': 29, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:07,671] Trial 19 finished with value: 0.8150000000000001 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 1918, 'learning_rate': 0.00012461096422980677, 'max_bin': 509, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:14,027] Trial 20 finished with value: 0.865 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1351, 'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:18,974] Trial 21 finished with value: 0.8750000000000002 and parameters: {'classifier': 'RandomForest', 'n_estimators': 952, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:23,967] Trial 22 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 977, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:29,023] Trial 23 finished with value: 0.8800000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 984, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:33,991] Trial 24 finished with value: 0.86 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1041, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:37,538] Trial 25 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 674, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:43,237] Trial 26 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1056, 'max_depth': 27, 'min_samples_split': 11, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:17:46,134] Trial 27 finished with value: 0.8675 and parameters: {'classifier': 'RandomForest', 'n_estimators': 592, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:31,752] Trial 28 finished with value: 0.8300000000000001 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 1771, 'learning_rate': 0.00097190475627906, 'max_bin': 590, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:35,700] Trial 29 finished with value: 0.85 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1191, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:42,496] Trial 30 finished with value: 0.86 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1524, 'max_depth': 26, 'min_samples_split': 8, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:47,631] Trial 31 finished with value: 0.8750000000000002 and parameters: {'classifier': 'RandomForest', 'n_estimators': 985, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:52,511] Trial 32 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 912, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:18:57,341] Trial 33 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 903, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:02,092] Trial 34 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 859, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:05,553] Trial 35 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 626, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:07,950] Trial 36 finished with value: 0.8700000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 478, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:26,378] Trial 37 finished with value: 0.825 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 791, 'learning_rate': 0.0009542611644287077, 'max_bin': 1068, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:28,642] Trial 38 finished with value: 0.8825000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 420, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:32,290] Trial 39 finished with value: 0.8474999999999999 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1133, 'max_depth': 29, 'min_samples_split': 24, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:34,143] Trial 40 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 340, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:37,829] Trial 41 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 661, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:42,602] Trial 42 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 865, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:46,354] Trial 43 finished with value: 0.875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 734, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:49,750] Trial 44 finished with value: 0.8800000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 637, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:52,156] Trial 45 finished with value: 0.5475000000000001 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 149, 'learning_rate': 0.00012670063797070176, 'max_bin': 1643, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:19:56,578] Trial 46 finished with value: 0.875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 886, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:00,387] Trial 47 finished with value: 0.8625 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1121, 'max_depth': 21, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:04,125] Trial 48 finished with value: 0.875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 733, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:11,136] Trial 49 finished with value: 0.8850000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1278, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:17,797] Trial 50 finished with value: 0.8525 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1492, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 20, 'bootstrap': True}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:24,699] Trial 51 finished with value: 0.8850000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1263, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:31,485] Trial 52 finished with value: 0.8825000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1248, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:39,211] Trial 53 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1456, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:47,995] Trial 54 finished with value: 0.8825000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1617, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:20:54,693] Trial 55 finished with value: 0.8724999999999999 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1283, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:01,537] Trial 56 finished with value: 0.8724999999999999 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1378, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:30,416] Trial 57 finished with value: 0.8275 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 1180, 'learning_rate': 0.0007814020230040562, 'max_bin': 798, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:37,332] Trial 58 finished with value: 0.86 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1583, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 16, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:40,727] Trial 59 finished with value: 0.8300000000000001 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1072, 'max_depth': 22, 'min_samples_split': 11, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:49,098] Trial 60 finished with value: 0.8625 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1709, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:52,221] Trial 61 finished with value: 0.8825 and parameters: {'classifier': 'RandomForest', 'n_estimators': 561, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:21:57,116] Trial 62 finished with value: 0.8800000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 929, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:01,587] Trial 63 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 820, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:09,026] Trial 64 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1312, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:16,359] Trial 65 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1425, 'max_depth': 27, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:22,948] Trial 66 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1242, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:28,486] Trial 67 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1002, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:32,480] Trial 68 finished with value: 0.8725000000000002 and parameters: {'classifier': 'RandomForest', 'n_estimators': 761, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:22:57,565] Trial 69 finished with value: 0.8150000000000001 and parameters: {'classifier': 'LightGBM', 'boosting_type': 'dart', 'n_estimators': 1037, 'learning_rate': 0.00031320699884542587, 'max_bin': 1522, 'importance_type': 'gain'}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:03,550] Trial 70 finished with value: 0.865 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1150, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:07,168] Trial 71 finished with value: 0.8825 and parameters: {'classifier': 'RandomForest', 'n_estimators': 655, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:10,969] Trial 72 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 689, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:13,437] Trial 73 finished with value: 0.8825000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 454, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:17,680] Trial 74 finished with value: 0.865 and parameters: {'classifier': 'RandomForest', 'n_estimators': 930, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 12, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:22,281] Trial 75 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 836, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:25,992] Trial 76 finished with value: 0.8549999999999999 and parameters: {'classifier': 'Extra Trees Classifier', 'n_estimators': 1102, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:28,819] Trial 77 finished with value: 0.875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 548, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:31,982] Trial 78 finished with value: 0.8800000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 594, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:34,002] Trial 79 finished with value: 0.8675 and parameters: {'classifier': 'RandomForest', 'n_estimators': 385, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:35,277] Trial 80 finished with value: 0.8850000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 234, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:36,955] Trial 81 finished with value: 0.875 and parameters: {'classifier': 'RandomForest', 'n_estimators': 305, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:38,158] Trial 82 finished with value: 0.8750000000000002 and parameters: {'classifier': 'RandomForest', 'n_estimators': 226, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:43,184] Trial 83 finished with value: 0.8825000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 909, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:47,304] Trial 84 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 768, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:51,979] Trial 85 finished with value: 0.885 and parameters: {'classifier': 'RandomForest', 'n_estimators': 851, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n",
            "[I 2025-03-25 15:23:58,591] Trial 86 finished with value: 0.8775000000000001 and parameters: {'classifier': 'RandomForest', 'n_estimators': 1259, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 14 with value: 0.8875.\n"
          ]
        }
      ],
      "source": [
        "# Create a study and optimize it using CmaEsSampler\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UUNgpnL5PKJZ",
      "metadata": {
        "id": "UUNgpnL5PKJZ"
      },
      "outputs": [],
      "source": [
        "# Retrieve the best trial\n",
        "best_trial = study.best_trial\n",
        "print(\"Best trial parameters:\", best_trial.params)\n",
        "print(\"Best trial accuracy:\", best_trial.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3wAeQaBFPKF2",
      "metadata": {
        "id": "3wAeQaBFPKF2"
      },
      "outputs": [],
      "source": [
        "study.trials_dataframe()['params_classifier'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wmM3qY4Tgq7v",
      "metadata": {
        "id": "wmM3qY4Tgq7v"
      },
      "outputs": [],
      "source": [
        "study.trials_dataframe().groupby('params_classifier')['value'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ydev5XzgwqDX",
      "metadata": {
        "id": "ydev5XzgwqDX"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.visualization import (\n",
        "    plot_optimization_history,\n",
        "    plot_slice,\n",
        "    plot_param_importances\n",
        ")\n",
        "# Check if the study contains completed trials before plotting\n",
        "if len(study.trials) > 0:\n",
        "    # Plot the optimization history\n",
        "    plot_optimization_history(study).show()\n",
        "\n",
        "    # Plot the slice plot\n",
        "    plot_slice(study).show()\n",
        "\n",
        "    # Plot hyperparameter importance\n",
        "    plot_param_importances(study).show()\n",
        "else:\n",
        "    print(\"No completed trials available for visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TnXrvyGz2ho4",
      "metadata": {
        "id": "TnXrvyGz2ho4"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88aumE70g9o1",
      "metadata": {
        "id": "88aumE70g9o1"
      },
      "source": [
        "False, 'class_weight': 'balanced', 'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ovf_-jct45T1",
      "metadata": {
        "id": "ovf_-jct45T1"
      },
      "source": [
        "### Train Random Forest Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7CEpMO-p46Mj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CEpMO-p46Mj",
        "outputId": "f570dbd9-9aca-4c1f-9f8a-ecfeeaed1811"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Define Random Forest Model with Given Hyperparameters\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=1180, max_depth=17, min_samples_split=9, min_samples_leaf=1, bootstrap=False\n",
        ")\n",
        "\n",
        "# Fit Model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "# Fit Model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vBNTpkqusVv6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "vBNTpkqusVv6",
        "outputId": "702ddbbc-cb93-47d0-cfa1-2d2160a988ac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances - Random Forest Model\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), np.array(X_train.columns)[indices], rotation=90)\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-VVqWcyb5T-c",
      "metadata": {
        "id": "-VVqWcyb5T-c"
      },
      "source": [
        "Print Classification Report and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wn7Ow9im5TYQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "wn7Ow9im5TYQ",
        "outputId": "882b33f9-551d-4e3d-ed44-182873bba563"
      },
      "outputs": [],
      "source": [
        "# Print Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix for Random Forest\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v5BIlIfI5c3s",
      "metadata": {
        "id": "v5BIlIfI5c3s"
      },
      "source": [
        "Perform 10-Fold Cross-Validation and Compute Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-lXUNsGq5RVO",
      "metadata": {
        "id": "-lXUNsGq5RVO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from lightgbm import LGBMClassifier\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=1180, max_depth=17, min_samples_split=9, min_samples_leaf=1, bootstrap=False, random_state=42\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "cv_scores = cross_val_score(rf_clf, X_train, y_train,\n",
        "                            cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
        "                            scoring='accuracy')\n",
        "\n",
        "# Assuming loss_values for each fold (you would replace this with actual loss values if available)\n",
        "# Example: Loss values for each fold (you might need to calculate these)\n",
        "loss_values = [1 - score for score in cv_scores]  # Just an example, assuming loss is 1 - accuracy\n",
        "\n",
        "# Accuracy Before Cross-validation (Example value, replace with your actual value)\n",
        "test_accuracy = 0.84  # Example value #########################################################################################################################################\n",
        "\n",
        "# Cross-validation accuracy\n",
        "cv_accuracy = np.mean(cv_scores)\n",
        "print(f\"cv_accuracy: {cv_accuracy:.4f}\")\n",
        "# Calculate log loss before cross-validation (using test set)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_prob_before = rf_clf.predict_proba(X_test)  # predicted probabilities\n",
        "log_loss_before = log_loss(y_test, y_pred_prob_before)\n",
        "\n",
        "# Calculate log loss after cross-validation (using cross_val_predict)\n",
        "y_pred_prob_after = cross_val_predict(rf_clf, X_train, y_train, cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42), method='predict_proba')\n",
        "log_loss_after = log_loss(y_train, y_pred_prob_after)\n",
        "\n",
        "# Create a figure with subplots (2 rows and 2 columns)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # Adjusted plot size\n",
        "\n",
        "# 1. Accuracy per Fold (Bar chart)\n",
        "axes[0, 0].bar(range(1, 11), cv_scores, color=[\n",
        "    'SkyBlue', 'Salmon', 'Tomato', 'MediumSeaGreen', 'RoyalBlue',\n",
        "    'SlateGray', 'Orchid', 'Goldenrod', 'Crimson', 'DodgerBlue'\n",
        "], edgecolor='black')\n",
        "for bar in axes[0, 0].bar(range(1, 11), cv_scores, color=[\n",
        "    'SkyBlue', 'Salmon', 'Tomato', 'MediumSeaGreen', 'RoyalBlue',\n",
        "    'SlateGray', 'Orchid', 'Goldenrod', 'Crimson', 'DodgerBlue'\n",
        "], edgecolor='black'):\n",
        "    height = bar.get_height()\n",
        "    axes[0, 0].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{height*100:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
        "axes[0, 0].set_xlabel('Fold')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].set_title('Accuracy per Fold (10-Fold Cross-Validation): Random Forest Classifier')\n",
        "axes[0, 0].set_xticks(range(1, 11))\n",
        "axes[0, 0].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# 2. Loss per Fold (Line graph)\n",
        "axes[0, 1].plot(range(1, 11), loss_values, marker='o', color='purple', label='Loss')\n",
        "axes[0, 1].set_xlabel('Fold')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].set_title('Loss per Fold (10-Fold Cross-Validation): Random Forest Classifier')\n",
        "axes[0, 1].set_xticks(range(1, 11))\n",
        "axes[0, 1].grid(True)\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. Box Plot for Accuracy Before and After Cross-validation\n",
        "axes[1, 0].boxplot([cv_scores, [test_accuracy] * 10], labels=['After CV', 'Before CV'])\n",
        "axes[1, 0].set_title('After Cross-validation Accuracy: Random Forest Classifier')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "\n",
        "# 4. Box Plot for Log Loss Before and After Cross-validation\n",
        "axes[1, 1].boxplot([np.array([log_loss_after] * 10), np.array([log_loss_before] * 10)],\n",
        "                   labels=['After CV', 'Before CV'])\n",
        "axes[1, 1].set_title('After Cross-validation Log Loss: Random Forest Classifier')\n",
        "axes[1, 1].set_ylabel('Log Loss')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()  # Adjust the layout so that the plots do not overlap\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7vRiNMW51-e",
      "metadata": {
        "id": "e7vRiNMW51-e"
      },
      "source": [
        "Precision-Recall Curve and Learning Curve for best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T3RPM2gR5Lbj",
      "metadata": {
        "id": "T3RPM2gR5Lbj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "import numpy as np\n",
        "\n",
        "# Precision-Recall Curve\n",
        "y_pred_proba =rf_clf.predict_proba(X_test)[:, 1]  # Probabilities for Precision-Recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "# Learning Curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(rf_clf, X_train, y_train, cv=10, n_jobs=-1)\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "test_mean = test_scores.mean(axis=1)\n",
        "train_std = train_scores.std(axis=1)\n",
        "test_std = test_scores.std(axis=1)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Precision-Recall Curve\n",
        "axes[0].plot(recall, precision, color='green', lw=2, label=f'Precision-Recall Curve (AUC = {pr_auc:.4f})')\n",
        "axes[0].set_xlabel('Recall')\n",
        "axes[0].set_ylabel('Precision')\n",
        "axes[0].set_title('Precision-Recall Curve')\n",
        "axes[0].legend(loc=\"lower left\")\n",
        "\n",
        "# Learning Curve\n",
        "axes[1].plot(train_sizes, train_mean, color='blue', label='Training Score')\n",
        "axes[1].plot(train_sizes, test_mean, color='green', label='Cross-Validation Score')\n",
        "axes[1].fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
        "axes[1].fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='green', alpha=0.2)\n",
        "axes[1].set_xlabel('Training Size')\n",
        "axes[1].set_ylabel('Score')\n",
        "axes[1].set_title('Learning Curve')\n",
        "axes[1].legend(loc=\"best\")\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dLzp5XZ6ezAg",
      "metadata": {
        "id": "dLzp5XZ6ezAg"
      },
      "source": [
        "## Apply Soft Voting and Hard Voting ensamble method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bG6SokPepa1",
      "metadata": {
        "id": "4bG6SokPepa1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define individual models with best parameters\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=1180, max_depth=17, min_samples_split=9, min_samples_leaf=1, bootstrap=False, random_state=42\n",
        ")\n",
        "\n",
        "et_model = ExtraTreesClassifier(\n",
        "    n_estimators=1097, max_depth=25, min_samples_split=12, min_samples_leaf=2, random_state=42\n",
        ")\n",
        "\n",
        "lgbm_model = LGBMClassifier(\n",
        "    boosting_type='dart', n_estimators=1830, learning_rate=0.000961, max_bin=1568, importance_type='gain', random_state=42\n",
        ")\n",
        "\n",
        "# Apply Hard Voting\n",
        "hard_voting_clf = VotingClassifier(\n",
        "    estimators=[('RF', rf_model), ('ET', et_model), ('LGBM', lgbm_model)],\n",
        "    voting='hard'  # Majority voting\n",
        ")\n",
        "\n",
        "# Apply Soft Voting\n",
        "soft_voting_clf = VotingClassifier(\n",
        "    estimators=[('RF', rf_model), ('ET', et_model), ('LGBM', lgbm_model)],\n",
        "    voting='soft'  # Probability-based voting\n",
        ")\n",
        "\n",
        "# Evaluate performance using cross-validation\n",
        "hard_voting_score = cross_val_score(hard_voting_clf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "soft_voting_score = cross_val_score(soft_voting_clf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "print(f\"Hard Voting Accuracy: {hard_voting_score:.4f}\")\n",
        "print(f\"Soft Voting Accuracy: {soft_voting_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tl7gH7A8wSae",
      "metadata": {
        "id": "tl7gH7A8wSae"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Individual model scores using cross-validation\n",
        "rf_score = cross_val_score(rf_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "et_score = cross_val_score(et_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "lgbm_score = cross_val_score(lgbm_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "# Accuracy scores\n",
        "models = ['Random Forest', 'Extra Trees', 'LightGBM', 'Hard Voting', 'Soft Voting']\n",
        "scores = [rf_score, et_score, lgbm_score, hard_voting_score, soft_voting_score]\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=models, y=scores, palette='viridis')\n",
        "\n",
        "# Add percentage value labels on top of the bars\n",
        "for i, v in enumerate(scores):\n",
        "    plt.text(i, v + 0.002, f\"{v * 100:.2f}%\", ha='center', fontsize=12)\n",
        "\n",
        "plt.ylim(min(scores) - 0.02, max(scores) + 0.02)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xticks(rotation=30)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IwJ31rEMgm0G",
      "metadata": {
        "id": "IwJ31rEMgm0G"
      },
      "source": [
        "### Bagging (Bootstrap Aggregating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8msB6ierepUs",
      "metadata": {
        "id": "8msB6ierepUs"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Bagging for RandomForest\n",
        "bagging_rf = BaggingClassifier(\n",
        "    estimator=rf_model,  # Change 'base_estimator' to 'estimator'\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Bagging for Extra Trees\n",
        "bagging_et = BaggingClassifier(\n",
        "    estimator=et_model,  # Change 'base_estimator' to 'estimator'\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Bagging for LightGBM\n",
        "bagging_lgbm = BaggingClassifier(\n",
        "    estimator=lgbm_model,  # Change 'base_estimator' to 'estimator'\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Evaluate Bagging performance\n",
        "bagging_rf_score = cross_val_score(bagging_rf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "bagging_et_score = cross_val_score(bagging_et, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "bagging_lgbm_score = cross_val_score(bagging_lgbm, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "print(f\"Bagging Random Forest Accuracy: {bagging_rf_score:.4f}\")\n",
        "print(f\"Bagging Extra Trees Accuracy: {bagging_et_score:.4f}\")\n",
        "print(f\"Bagging LightGBM Accuracy: {bagging_lgbm_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5OCDzhw0gzJu",
      "metadata": {
        "id": "5OCDzhw0gzJu"
      },
      "source": [
        "### Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NQrwjUc2tnCY",
      "metadata": {
        "id": "NQrwjUc2tnCY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Boosting for RandomForest using AdaBoost\n",
        "boosting_rf = AdaBoostClassifier(\n",
        "    estimator=rf_model,  # Change 'base_estimator' to 'estimator'\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Boosting for Extra Trees using AdaBoost\n",
        "boosting_et = AdaBoostClassifier(\n",
        "    estimator=et_model,  # Change 'base_estimator' to 'estimator'\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Boosting for LightGBM using XGBoost (can also use LightGBM's own boosting)\n",
        "boosting_lgbm = XGBClassifier(\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Evaluate Boosting performance\n",
        "boosting_rf_score = cross_val_score(boosting_rf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "boosting_et_score = cross_val_score(boosting_et, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "boosting_lgbm_score = cross_val_score(boosting_lgbm, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "print(f\"Boosting Random Forest Accuracy: {boosting_rf_score:.4f}\")\n",
        "print(f\"Boosting Extra Trees Accuracy: {boosting_et_score:.4f}\")\n",
        "print(f\"Boosting LightGBM Accuracy: {boosting_lgbm_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RNpu4M3DhDqE",
      "metadata": {
        "id": "RNpu4M3DhDqE"
      },
      "source": [
        "### Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aPlLu66UepP4",
      "metadata": {
        "id": "aPlLu66UepP4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', rf_model),\n",
        "    ('et', et_model),\n",
        "    ('lgbm', lgbm_model)\n",
        "]\n",
        "\n",
        "# Meta-model (logistic regression can be a simple choice for stacking)\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model\n",
        ")\n",
        "\n",
        "# Evaluate Stacking performance\n",
        "stacking_score = cross_val_score(stacking_clf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "print(f\"Stacking Classifier Accuracy: {stacking_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qx-svqN2hRBs",
      "metadata": {
        "id": "Qx-svqN2hRBs"
      },
      "source": [
        "### Comparison of All Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jJshnEt_epJ3",
      "metadata": {
        "id": "jJshnEt_epJ3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# List all methods and their corresponding scores\n",
        "methods = ['Bagging RF', 'Bagging ET', 'Bagging LGBM', 'Boosting RF', 'Boosting ET', 'Boosting LGBM', 'Stacking']\n",
        "scores = [bagging_rf_score, bagging_et_score, bagging_lgbm_score, boosting_rf_score, boosting_et_score, boosting_lgbm_score, stacking_score]\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=methods, y=scores, palette='viridis')\n",
        "\n",
        "# Add percentage value labels on top of the bars\n",
        "for i, v in enumerate(scores):\n",
        "    plt.text(i, v + 0.002, f\"{v * 100:.2f}%\", ha='center', fontsize=12)\n",
        "\n",
        "plt.ylim(min(scores) - 0.02, max(scores) + 0.02)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Comparison of Ensemble Methods')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17A4d9UOzMBw",
      "metadata": {
        "id": "17A4d9UOzMBw"
      },
      "source": [
        "## Save the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "StXzBGBzN91l",
      "metadata": {
        "id": "StXzBGBzN91l"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Best parameters\n",
        "best_params = {\n",
        "    'n_estimators': 1180,\n",
        "    'max_depth': 17,\n",
        "    'min_samples_split': 9,\n",
        "    'min_samples_leaf': 1,\n",
        "    'bootstrap': False,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Define Random Forest model with the best parameters\n",
        "best_rf_clf = RandomForestClassifier(**best_params)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "cross_val_scores = cross_val_score(best_rf_clf, X_train, y_train, cv=10, scoring='accuracy')\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(f\"Cross-validation scores: {cross_val_scores}\")\n",
        "print(f\"Mean cross-validation score: {cross_val_scores.mean():.4f}\")\n",
        "\n",
        "# Fit the model on the entire training set\n",
        "best_rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(best_rf_clf, 'best_rf_model.pkl')\n",
        "\n",
        "print(\"Model saved as 'best_rf_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7FIyT2Nqz6o9",
      "metadata": {
        "id": "7FIyT2Nqz6o9"
      },
      "source": [
        "### Deploy the Model using Flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1GdwPC3z-TP",
      "metadata": {
        "id": "d1GdwPC3z-TP"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = joblib.load('best_rf_model.pkl')\n",
        "\n",
        "# Define a prediction endpoint\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the features from the request\n",
        "    data = request.get_json()\n",
        "\n",
        "    # Extract features from the data\n",
        "    features = np.array(data['features']).reshape(1, -1)\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    prediction = model.predict(features)\n",
        "\n",
        "    # Return the prediction as a JSON response\n",
        "    return jsonify({'prediction': int(prediction[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NrWSb7n4Uy0P",
      "metadata": {
        "id": "NrWSb7n4Uy0P"
      },
      "source": [
        "#                                                        THE END"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "HF",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02afc956a2ea48768e804099ed0681b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e3ac82673c49f39ae2fe9cc75c7b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0797560977f14cc49cf9b8be89568692": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09cd13a302824fa3b378c5706011345e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfe2a7bac664ade9373bd938296eab8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5db7148fb442f8a1b3a43d1b4bc54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0797560977f14cc49cf9b8be89568692",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b6361c1f6f4d8a860dcf58df2e8c99",
            "value": 1
          }
        },
        "2690837e7395446f9e428e6139138628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2722e070b2954201bfbccddac85cf4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35824ba707724c3181518a1de20bec51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45605bbc649c45a2bd93cf0736d98bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5419cbdf47f243e5b30485d7a1efb3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6352801f4f724fbfad5cc352ed993622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c0d078b574472f962c8b5f03638357",
            "placeholder": "​",
            "style": "IPY_MODEL_7c3824a14edb4fdeaf09fe74676bfd61",
            "value": "Summarize dataset: 100%"
          }
        },
        "685602690c9e466daf96aaece7a46d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6bbccaf520946a3bcdfddfa82e78410",
            "placeholder": "​",
            "style": "IPY_MODEL_2690837e7395446f9e428e6139138628",
            "value": " 1/1 [00:10&lt;00:00, 10.09s/it]"
          }
        },
        "7bf254ed55c54ee2ba09ec7b22ef2a60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3824a14edb4fdeaf09fe74676bfd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91d1dbed6d0c48bc861d14070a4efd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a044381974455e9dec5e9b366b61e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b6361c1f6f4d8a860dcf58df2e8c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b0db360a13243d8bb2378cbc0a8e928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09cd13a302824fa3b378c5706011345e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45605bbc649c45a2bd93cf0736d98bb9",
            "value": 5
          }
        },
        "9be5934c597b4226b22bc72b75c44cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ddce267b7bc4b628b07ca707e1653ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ebfd2740754667bbaf2d97a5389ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_92a044381974455e9dec5e9b366b61e3",
            "value": " 1/1 [00:11&lt;00:00, 11.65s/it]"
          }
        },
        "a0c0d078b574472f962c8b5f03638357": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58a563b20704ccba61bf8de25db7a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6352801f4f724fbfad5cc352ed993622",
              "IPY_MODEL_9b0db360a13243d8bb2378cbc0a8e928",
              "IPY_MODEL_d4ac432b3022482f9551c8dff03e6973"
            ],
            "layout": "IPY_MODEL_35824ba707724c3181518a1de20bec51"
          }
        },
        "c62e5abc51b74e20aef880e64c74c3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee9658d8a8a2451db5de924cb8dc26a8",
              "IPY_MODEL_ec51562a27004d61a78a459ae59f63c0",
              "IPY_MODEL_9ddce267b7bc4b628b07ca707e1653ac"
            ],
            "layout": "IPY_MODEL_91d1dbed6d0c48bc861d14070a4efd9e"
          }
        },
        "d4ac432b3022482f9551c8dff03e6973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf254ed55c54ee2ba09ec7b22ef2a60",
            "placeholder": "​",
            "style": "IPY_MODEL_5419cbdf47f243e5b30485d7a1efb3dc",
            "value": " 783/783 [01:09&lt;00:00,  9.73it/s, Completed]"
          }
        },
        "dce89f969e8f4d71b3868410d9f47912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df9b6cecf4fa4c2e954d1fed3302d086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bfe2a7bac664ade9373bd938296eab8",
            "placeholder": "​",
            "style": "IPY_MODEL_dce89f969e8f4d71b3868410d9f47912",
            "value": "Generate report structure: 100%"
          }
        },
        "e3b4f810a6aa4100b89b6f65b1e781fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df9b6cecf4fa4c2e954d1fed3302d086",
              "IPY_MODEL_1c5db7148fb442f8a1b3a43d1b4bc54e",
              "IPY_MODEL_685602690c9e466daf96aaece7a46d17"
            ],
            "layout": "IPY_MODEL_02afc956a2ea48768e804099ed0681b6"
          }
        },
        "e5c2c72ba4e34ebdb02a12ac28d88eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6bbccaf520946a3bcdfddfa82e78410": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec51562a27004d61a78a459ae59f63c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2722e070b2954201bfbccddac85cf4e6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5c2c72ba4e34ebdb02a12ac28d88eb8",
            "value": 1
          }
        },
        "ee9658d8a8a2451db5de924cb8dc26a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be5934c597b4226b22bc72b75c44cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_05e3ac82673c49f39ae2fe9cc75c7b01",
            "value": "Render HTML: 100%"
          }
        },
        "f2ebfd2740754667bbaf2d97a5389ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
